{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "631357b1-327f-45a2-ba4e-87d21ac1a0a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "XTzBUFWQ-OWj"
   },
   "source": [
    "# Project: Prompt Engineering with LangChain and ChatGPT for real-world tasks\n",
    "\n",
    "In this notebook you will leverage ChatGPT and LangChain to solve and do a few mini-projects based on some real-world scenarios:\n",
    "\n",
    "- Mini-Project 1: Review Analyst\n",
    "- Mini-Project 2: Research Paper Analyst\n",
    "- Mini-Project 3: Social Media Marketing Analyst\n",
    "- Mini-Project 4: IT Support Analyst\n",
    "\n",
    "___[Created By: Dipanjan (DJ)](https://www.linkedin.com/in/dipanjans/)___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17630c1a-3373-47f8-8fc7-d979a90bf582",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "L1KvMtf54l0d"
   },
   "source": [
    "## Install OpenAI and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "435dda06-fc9c-49fa-a113-89d5001e06dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting langchain==0.3.11\n  Downloading langchain-0.3.11-py3-none-any.whl (1.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 12.3 MB/s eta 0:00:00\nRequirement already satisfied: numpy<2,>=1.22.4 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.3.11) (1.23.5)\nCollecting pydantic<3.0.0,>=2.7.4\n  Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 431.8/431.8 kB 17.1 MB/s eta 0:00:00\nCollecting PyYAML>=5.3\n  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 751.2/751.2 kB 21.8 MB/s eta 0:00:00\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.3.11) (2.28.1)\nCollecting langsmith<0.3,>=0.1.17\n  Downloading langsmith-0.2.10-py3-none-any.whl (326 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 326.4/326.4 kB 19.4 MB/s eta 0:00:00\nCollecting SQLAlchemy<3,>=1.4\n  Downloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 37.9 MB/s eta 0:00:00\nCollecting aiohttp<4.0.0,>=3.8.3\n  Downloading aiohttp-3.11.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 43.1 MB/s eta 0:00:00\nCollecting langchain-text-splitters<0.4.0,>=0.3.0\n  Downloading langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\nCollecting async-timeout<5.0.0,>=4.0.0\n  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.3.11) (8.1.0)\nCollecting langchain-core<0.4.0,>=0.3.24\n  Downloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 411.6/411.6 kB 29.7 MB/s eta 0:00:00\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (22.1.0)\nCollecting multidict<7.0,>=4.5\n  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.6/124.6 kB 13.2 MB/s eta 0:00:00\nCollecting frozenlist>=1.1.1\n  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 241.9/241.9 kB 16.5 MB/s eta 0:00:00\nCollecting aiohappyeyeballs>=2.3.0\n  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\nCollecting propcache>=0.2.0\n  Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 205.1/205.1 kB 24.7 MB/s eta 0:00:00\nCollecting aiosignal>=1.1.2\n  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\nCollecting yarl<2.0,>=1.17.0\n  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 319.7/319.7 kB 36.0 MB/s eta 0:00:00\nRequirement already satisfied: packaging<25,>=23.2 in /databricks/python3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain==0.3.11) (23.2)\nCollecting typing-extensions>=4.7\n  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\nCollecting jsonpatch<2.0,>=1.33\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nCollecting requests-toolbelt<2.0.0,>=1.0.0\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 7.4 MB/s eta 0:00:00\nCollecting httpx<1,>=0.23.0\n  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.5/73.5 kB 8.5 MB/s eta 0:00:00\nCollecting orjson<4.0.0,>=3.9.14\n  Downloading orjson-3.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.4/130.4 kB 9.9 MB/s eta 0:00:00\nCollecting annotated-types>=0.6.0\n  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nCollecting pydantic-core==2.27.2\n  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 53.3 MB/s eta 0:00:00\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.11) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.11) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.11) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.11) (3.4)\nCollecting greenlet!=0.4.17\n  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 599.5/599.5 kB 38.0 MB/s eta 0:00:00\nCollecting httpcore==1.*\n  Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.6/78.6 kB 10.2 MB/s eta 0:00:00\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (3.5.0)\nCollecting h11<0.15,>=0.13\n  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 6.5 MB/s eta 0:00:00\nCollecting jsonpointer>=1.9\n  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (1.2.0)\nInstalling collected packages: typing-extensions, PyYAML, propcache, orjson, jsonpointer, h11, greenlet, frozenlist, async-timeout, annotated-types, aiohappyeyeballs, SQLAlchemy, requests-toolbelt, pydantic-core, multidict, jsonpatch, httpcore, aiosignal, yarl, pydantic, httpx, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.4.0\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.10.6\n    Not uninstalling pydantic at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb\n    Can't uninstall 'pydantic'. No files were found to uninstall.\nSuccessfully installed PyYAML-6.0.2 SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 annotated-types-0.7.0 async-timeout-4.0.3 frozenlist-1.5.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.11 langchain-core-0.3.29 langchain-text-splitters-0.3.5 langsmith-0.2.10 multidict-6.1.0 orjson-3.10.14 propcache-0.2.1 pydantic-2.10.4 pydantic-core-2.27.2 requests-toolbelt-1.0.0 typing-extensions-4.12.2 yarl-1.18.3\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting langchain-openai==0.2.12\n  Downloading langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.7/50.7 kB 2.1 MB/s eta 0:00:00\nCollecting openai<2.0.0,>=1.55.3\n  Downloading openai-1.59.5-py3-none-any.whl (454 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 454.8/454.8 kB 8.3 MB/s eta 0:00:00\nCollecting tiktoken<1,>=0.7\n  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 16.0 MB/s eta 0:00:00\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain-openai==0.2.12) (0.3.29)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.33)\nRequirement already satisfied: PyYAML>=5.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (6.0.2)\nRequirement already satisfied: typing-extensions>=4.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (4.12.2)\nRequirement already satisfied: langsmith<0.3,>=0.1.125 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.2.10)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.10.4)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /databricks/python3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (8.1.0)\nRequirement already satisfied: packaging<25,>=23.2 in /databricks/python3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (23.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.28.1)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.10/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.7.0)\nCollecting jiter<1,>=0.4.0\n  Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 345.0/345.0 kB 15.3 MB/s eta 0:00:00\nCollecting tqdm>4\n  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 11.3 MB/s eta 0:00:00\nRequirement already satisfied: anyio<5,>=3.5.0 in /databricks/python3/lib/python3.10/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (3.5.0)\nCollecting regex>=2022.1.18\n  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.7/781.7 kB 19.4 MB/s eta 0:00:00\nRequirement already satisfied: requests>=2.26.0 in /databricks/python3/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.12) (2.28.1)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (3.4)\nRequirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.0.7)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (2022.12.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.10.14)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.0.0)\nRequirement already satisfied: pydantic-core==2.27.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.27.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.7.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.12) (1.26.14)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.12) (2.0.4)\nInstalling collected packages: tqdm, regex, jiter, tiktoken, openai, langchain-openai\nSuccessfully installed jiter-0.8.2 langchain-openai-0.2.12 openai-1.59.5 regex-2024.11.6 tiktoken-0.8.0 tqdm-4.67.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting langchain-community==0.3.11\n  Downloading langchain_community-0.3.11-py3-none-any.whl (2.5 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 14.0 MB/s eta 0:00:00\nRequirement already satisfied: numpy<2,>=1.22.4 in /databricks/python3/lib/python3.10/site-packages (from langchain-community==0.3.11) (1.23.5)\nCollecting pydantic-settings<3.0.0,>=2.4.0\n  Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /databricks/python3/lib/python3.10/site-packages (from langchain-community==0.3.11) (8.1.0)\nCollecting httpx-sse<0.5.0,>=0.4.0\n  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain-community==0.3.11) (2.0.36)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain-community==0.3.11) (0.3.29)\nRequirement already satisfied: langsmith<0.3,>=0.1.125 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain-community==0.3.11) (0.2.10)\nCollecting dataclasses-json<0.7,>=0.5.7\n  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from langchain-community==0.3.11) (2.28.1)\nRequirement already satisfied: langchain<0.4.0,>=0.3.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain-community==0.3.11) (0.3.11)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain-community==0.3.11) (3.11.11)\nRequirement already satisfied: PyYAML>=5.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain-community==0.3.11) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (2.4.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.18.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (22.1.0)\nCollecting typing-inspect<1,>=0.4.0\n  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nCollecting marshmallow<4.0.0,>=3.18.0\n  Downloading marshmallow-3.24.2-py3-none-any.whl (49 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.3/49.3 kB 5.3 MB/s eta 0:00:00\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (0.3.5)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (2.10.4)\nRequirement already satisfied: typing-extensions>=4.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (4.12.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /databricks/python3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (23.2)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (3.10.14)\nCollecting python-dotenv>=0.21.0\n  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.3.11) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.3.11) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.3.11) (2.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.3.11) (1.26.14)\nRequirement already satisfied: greenlet!=0.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.11) (3.1.1)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (3.5.0)\nRequirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b92dffc6-fd91-4e0c-90b7-9ca214a2b2bb/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (2.27.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11) (0.4.3)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.2.0)\nInstalling collected packages: typing-inspect, python-dotenv, marshmallow, httpx-sse, dataclasses-json, pydantic-settings, langchain-community\nSuccessfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.11 marshmallow-3.24.2 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.3.11\n",
    "!pip install langchain-openai==0.2.12\n",
    "!pip install langchain-community==0.3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fa8c790-80ea-4a68-8506-51b8f65d8e1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8435e955-31a4-4b16-855c-1bc0ee15785b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PtBa7rlWJWH3"
   },
   "source": [
    "## Enter API Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28ce8c0c-4c4a-4388-bd3d-c33c31371910",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Y6RD7As2sm8G"
   },
   "source": [
    "#### Enter your Open AI Key here\n",
    "\n",
    "You can get the key from [here](https://platform.openai.com/api-keys) after creating an account or signing in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77980500-15ee-49ce-94c9-353cd7ea2881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ogxBkS6ZnnC",
    "outputId": "4b411016-531d-4c31-85fc-b06cac039cc7"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Please enter your Open AI API Key here:  [REDACTED]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Please enter your Open AI API Key here: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "baf060a0-9514-4bda-9675-ff1c7d0148c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "T5rOqCyianbP"
   },
   "source": [
    "## Setup necessary system environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c9c861c-d697-4909-8f0b-42dc4708cf3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1PIStD04Zp9p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe0b21d1-f924-4f1f-85de-f4b2332dbe02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "VDWhgxCy5bA6"
   },
   "source": [
    "## Load Necessary Dependencies and ChatGPT LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec502dc1-581b-4620-8773-657411b59920",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9GYhyRFRuJXG"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e827dcff-9c1a-415a-b8dc-495b593c26a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "mY2bapqfuWq1"
   },
   "outputs": [],
   "source": [
    "chatgpt = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f2f1415-d63e-437c-98bc-d236b3b6210b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "AeDkpvGDhMGV"
   },
   "source": [
    "## Mini-Project 1: Review Analyst\n",
    "\n",
    "You are building an AI system to be able to look at customer reviews and do some complex analysis. for each review get ChatGPT to do the following:\n",
    "\n",
    "  - Summarize the review. The summary should be at most 3 lines.\n",
    "  - Highlight both the positives and negatives\n",
    "  - Display the overall sentiment of the review (positive, negative, neutral)\n",
    "  - Display a list of 3 - 5 emotions expressed by the customer in the review\n",
    "  - If the sentiment is positive or neutral write an email and thank them for the review\n",
    "  - If the sentiment is negative apologize and write an email with an appropriate response\n",
    "\n",
    "Try to get the response in a nice structured format using an output parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4446b4cc-f2d7-42e7-a28a-f245b4e17e12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9P_TrLpRAIXM"
   },
   "source": [
    "### Access Customer Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91dc7726-3154-45f5-9526-e70024e68625",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "hRbBZB57hT0G"
   },
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    f\"\"\"\n",
    "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
    "    The sound quality is impressively clear with just the right amount of bass.\n",
    "    It's also waterproof, which tested true during a recent splashing incident.\n",
    "    Though it's compact, the volume can really fill the space.\n",
    "    The price was a bargain for such high-quality sound.\n",
    "    Shipping was also on point, arriving two days early in secure packaging.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Purchased a new gaming keyboard because of its rave reviews about responsiveness and backlighting.\n",
    "    It hasn't disappointed. The keys have a satisfying click and the LED colors are vibrant,\n",
    "    enhancing my gaming experience significantly. Price-wise, it's quite competitive,\n",
    "    and I feel like I got a good deal. The delivery was swift, and it came well-protected,\n",
    "    ensuring no damage during transport.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Ordered a set of wireless earbuds for running, and they've been a letdown.\n",
    "    The sound constantly cuts out, and the fit is uncomfortable after only a few minutes of use.\n",
    "    They advertised a 12-hour battery life, but I'm barely getting four hours.\n",
    "    Considering the cost, I expected better quality and performance.\n",
    "    They did arrive on time, but the positives end there. I'm already looking into a return.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    The tablet stand I bought was touted as being sturdy and adjustable,\n",
    "    but it's anything but. It wobbles with the slightest touch,\n",
    "    and the angles are not holding up as promised. It feels like a breeze could knock it over.\n",
    "    It was also pricier than others I've seen, which adds to the disappointment.\n",
    "    It did arrive promptly, but what's the use if the product doesn't meet basic expectations?\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Needed a new kitchen blender, but this model has been a nightmare.\n",
    "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
    "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
    "    I thought the brand meant quality, but this product has proven me wrong.\n",
    "    Plus, it arrived three days late. Definitely not worth the expense.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48828d33-eec3-451d-a9ff-58d94f50563e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Rz9SIYmYALOm"
   },
   "source": [
    "### Define Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6728d78e-6b92-43ee-91f7-3d7cb5833c2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "HK0u7biN7uDh"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define your desired data structure - like a python data class.\n",
    "class ReviewAnalysisResponse(BaseModel):\n",
    "    summary: str = Field(description=\"A brief summary of the customer review with maximum 3 lines\")\n",
    "    positives: list = Field(description=\"A list showing the positives mentioned by the customer in the review if any - max 3 points\")\n",
    "    negatives: list = Field(description=\"A list showing the negatives mentioned by the customer in the review if any - max 3 points\")\n",
    "    sentiment: str = Field(description=\"One word showing the sentiment of the review - positive, negative or neutral\")\n",
    "    emotions: list = Field(description=\"A list of 3 - 5 emotions expressed by the customer in the review\")\n",
    "    email: str = Field(description=\"Detailed email to the customer based on the sentiment\")\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=ReviewAnalysisResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95ce0b49-edd7-48b0-b1a1-63cafd4179ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Fc8awL6dAONh"
   },
   "source": [
    "### Create the input prompt for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85ebd6f8-a922-4815-bc3a-9f51d2828a51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "0TylxOCZ85O1"
   },
   "outputs": [],
   "source": [
    "# create the final prompt with formatting instructions from the parser\n",
    "prompt_txt = \"\"\"\n",
    "             Analyze the given customer review below and generate the response based on the instructions\n",
    "             mentioned below in the format instructions.\n",
    "             Also remember to write a detailed email response for the email field based on these conditions:\n",
    "               - email should be addressed to Dear Customer and signed with Service Agent\n",
    "               - thank them if the review is positive or neutral\n",
    "               - apologize if the review is negative\n",
    "\n",
    "             Format Instructions:\n",
    "             {format_instructions}\n",
    "\n",
    "             Review:\n",
    "             {review}\n",
    "            \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_txt,\n",
    "    input_variables=[\"review\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fea28ae-bd14-488f-83ca-7d688e51a842",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EE0l_m31AQ5k"
   },
   "source": [
    "### Create a LCEL LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cec1070-102a-4e18-8b32-f57a6228be95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "SWfHWjm-9HuD"
   },
   "outputs": [],
   "source": [
    "# create a simple LCEL chain to take the prompt, pass it to the LLM, enforce response format using the parser\n",
    "chain = (prompt\n",
    "           |\n",
    "         chatgpt\n",
    "           |\n",
    "         parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c80d0e2e-ed1c-431c-b1e1-f7aa261c77cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "70ivaPOrATnR"
   },
   "source": [
    "### Format the input reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b02838f-0d84-48eb-8814-2ba7934277b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBPSeLKA9N5M",
    "outputId": "824d7e82-06d4-4ac4-a4d3-8a8f2df74a2f"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'review': \"\\n    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\\n    The sound quality is impressively clear with just the right amount of bass.\\n    It's also waterproof, which tested true during a recent splashing incident.\\n    Though it's compact, the volume can really fill the space.\\n    The price was a bargain for such high-quality sound.\\n    Shipping was also on point, arriving two days early in secure packaging.\\n    \"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_formatted = [{'review': review} for review in reviews]\n",
    "reviews_formatted[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a292be73-5595-4b9b-9aac-5c5982adf90b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "MHbJvZlYAVcH"
   },
   "source": [
    "### Get responses from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5830a82-3fc0-4976-9484-addc3bc4e983",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tpH9R-iO9Wbq"
   },
   "outputs": [],
   "source": [
    "responses = chain.map().invoke(reviews_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "711040eb-ce85-47d8-ba13-f3d81d51ac63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "z7wS4_lnAYAL"
   },
   "source": [
    "### View LLM responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dab423a5-e5fe-4be7-a4ac-b00d8b4245ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NaC9oaRY-15M",
    "outputId": "2f2b0706-b14e-4af8-9b94-5f8d0901d911"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ReviewAnalysisResponse(summary='The customer is very pleased with the Bluetooth speaker, highlighting its sound quality, waterproof feature, and compact design. They also appreciated the early shipping and secure packaging.', positives=['Impressive sound quality with clear audio and good bass', 'Waterproof feature tested successfully', 'Compact design with powerful volume'], negatives=[], sentiment='positive', emotions=['satisfaction', 'happiness', 'excitement'], email=\"Dear Customer,\\n\\nThank you for your wonderful review! We're thrilled to hear that you are enjoying your new Bluetooth speaker and that it met your expectations in terms of sound quality, waterproof capability, and compact design. It's great to know that the early shipping and secure packaging added to your positive experience.\\n\\nIf you have any further questions or need assistance, feel free to reach out. We appreciate your support and hope you have many fantastic beach outings with your speaker!\\n\\nBest regards,\\nService Agent\")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33873ad6-52a7-40f3-bf14-caefe253d5ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VN7PfKvBbGZV",
    "outputId": "fc05d56f-7586-433a-be5a-fcc8ff63ce6d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/2256/command-3389206174236837-632561186:1: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n  responses[0].dict()\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'summary': 'The customer is very pleased with the Bluetooth speaker, highlighting its sound quality, waterproof feature, and compact design. They also appreciated the early shipping and secure packaging.',\n",
       " 'positives': ['Impressive sound quality with clear audio and good bass',\n",
       "  'Waterproof feature tested successfully',\n",
       "  'Compact design with powerful volume'],\n",
       " 'negatives': [],\n",
       " 'sentiment': 'positive',\n",
       " 'emotions': ['satisfaction', 'happiness', 'excitement'],\n",
       " 'email': \"Dear Customer,\\n\\nThank you for your wonderful review! We're thrilled to hear that you are enjoying your new Bluetooth speaker and that it met your expectations in terms of sound quality, waterproof capability, and compact design. It's great to know that the early shipping and secure packaging added to your positive experience.\\n\\nIf you have any further questions or need assistance, feel free to reach out. We appreciate your support and hope you have many fantastic beach outings with your speaker!\\n\\nBest regards,\\nService Agent\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64d19cf9-8980-4380-8183-69c685fff176",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dHJpeC5f9ZfK",
    "outputId": "de7bfe78-63db-45c5-c40b-493a9f714538"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary:\nThe customer is very pleased with the Bluetooth speaker, highlighting its sound quality, waterproof feature, and compact design. They also appreciated the early shipping and secure packaging.\npositives:\n['Impressive sound quality with clear audio and good bass', 'Waterproof feature tested successfully', 'Compact design with powerful volume']\nnegatives:\n[]\nsentiment:\npositive\nemotions:\n['satisfaction', 'happiness', 'excitement']\nemail:\nDear Customer,\n\nThank you for your wonderful review! We're thrilled to hear that you are enjoying your new Bluetooth speaker and that it met your expectations in terms of sound quality, waterproof capability, and compact design. It's great to know that the early shipping and secure packaging added to your positive experience.\n\nIf you have any further questions or need assistance, feel free to reach out. We appreciate your support and hope you have many fantastic beach outings with your speaker!\n\nBest regards,\nService Agent\n-----\n\n\nsummary:\nThe customer is highly satisfied with their new gaming keyboard, praising its responsiveness, backlighting, and competitive pricing. They also appreciated the swift delivery and protective packaging.\npositives:\n['Responsive keys with a satisfying click', 'Vibrant LED colors enhancing gaming experience', 'Competitive pricing and good deal']\nnegatives:\n[]\nsentiment:\npositive\nemotions:\n['satisfaction', 'excitement', 'contentment']\nemail:\nDear Customer,\n\nThank you for your wonderful review! We are thrilled to hear that you are enjoying your new gaming keyboard and that it has met your expectations in terms of responsiveness and backlighting. It's great to know that you found the pricing competitive and that the delivery was swift and secure.\n\nYour feedback is invaluable to us, and we appreciate you taking the time to share your experience. If you have any further questions or need assistance, please don't hesitate to reach out.\n\nBest regards,\nService Agent\n-----\n\n\nsummary:\nThe customer is disappointed with the wireless earbuds due to sound issues, uncomfortable fit, and poor battery life. They are considering a return.\npositives:\n['Arrived on time']\nnegatives:\n['Sound constantly cuts out', 'Uncomfortable fit after a few minutes', 'Battery life only lasts four hours instead of advertised 12 hours']\nsentiment:\nnegative\nemotions:\n['disappointment', 'frustration', 'dissatisfaction']\nemail:\nDear Customer,\n\nThank you for your feedback regarding the wireless earbuds. We sincerely apologize for the issues you have experienced with the sound quality, fit, and battery life. Your satisfaction is important to us, and we understand how disappointing it can be when a product does not meet your expectations. \n\nPlease let us know if you would like assistance with the return process or if there is anything else we can do to help resolve this matter.\n\nThank you for bringing this to our attention.\n\nBest regards,\nService Agent\n-----\n\n\nsummary:\nThe customer is disappointed with the tablet stand's stability and adjustability, feeling it does not meet expectations. They also mention the high price as a factor in their dissatisfaction.\npositives:\n['Arrived promptly']\nnegatives:\n['Wobbles with the slightest touch', 'Angles do not hold up as promised', 'Pricier than other options']\nsentiment:\nnegative\nemotions:\n['disappointment', 'frustration', 'dissatisfaction']\nemail:\nDear Customer,\n\nThank you for your feedback regarding the tablet stand. We sincerely apologize for the disappointment you experienced with its stability and adjustability. We strive to provide high-quality products, and it seems we fell short in this instance. Your comments about the pricing and performance are invaluable to us, and we will take them into consideration for future improvements.\n\nIf there's anything we can do to assist you further or if you would like to discuss this matter, please feel free to reach out.\n\nThank you for your understanding.\n\nBest regards,\nService Agent\n-----\n\n\nsummary:\nThe customer had a negative experience with the kitchen blender, citing performance issues and delivery delays.\npositives:\n[]\nnegatives:\n['Struggles with tougher foods', 'Incredibly noisy', \"'Easy-clean' feature is ineffective\", 'Arrived three days late']\nsentiment:\nnegative\nemotions:\n['frustration', 'disappointment', 'anger']\nemail:\nDear Customer,\n\nThank you for taking the time to share your feedback regarding the kitchen blender. We sincerely apologize for the issues you experienced with its performance, noise level, and the delivery delay. Your satisfaction is important to us, and we are committed to addressing these concerns. Please feel free to reach out if you have any further questions or need assistance.\n\nBest regards,\nService Agent\n-----\n\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/2256/command-3389206174236838-2992996444:2: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n  for k,v in response.dict().items():\n"
     ]
    }
   ],
   "source": [
    "for response in responses:\n",
    "  for k,v in response.dict().items():\n",
    "    print(f'{k}:\\n{v}')\n",
    "  print('-----')\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e2bed6f-33a4-4553-b276-80b15507fd7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "4VgCY3aV-7AI",
    "outputId": "252507c5-ecfa-4fff-f47e-34e42f92ba2f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/2256/command-3389206174236839-1175396765:3: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n  pd.DataFrame(response.dict() for response in responses)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>emotions</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The customer is very pleased with the Bluetoot...</td>\n",
       "      <td>[Impressive sound quality with clear audio and...</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>[satisfaction, happiness, excitement]</td>\n",
       "      <td>Dear Customer,\\n\\nThank you for your wonderful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The customer is highly satisfied with their ne...</td>\n",
       "      <td>[Responsive keys with a satisfying click, Vibr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>[satisfaction, excitement, contentment]</td>\n",
       "      <td>Dear Customer,\\n\\nThank you for your wonderful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The customer is disappointed with the wireless...</td>\n",
       "      <td>[Arrived on time]</td>\n",
       "      <td>[Sound constantly cuts out, Uncomfortable fit ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[disappointment, frustration, dissatisfaction]</td>\n",
       "      <td>Dear Customer,\\n\\nThank you for your feedback ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The customer is disappointed with the tablet s...</td>\n",
       "      <td>[Arrived promptly]</td>\n",
       "      <td>[Wobbles with the slightest touch, Angles do n...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[disappointment, frustration, dissatisfaction]</td>\n",
       "      <td>Dear Customer,\\n\\nThank you for your feedback ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The customer had a negative experience with th...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Struggles with tougher foods, Incredibly nois...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[frustration, disappointment, anger]</td>\n",
       "      <td>Dear Customer,\\n\\nThank you for taking the tim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  ...                                              email\n",
       "0  The customer is very pleased with the Bluetoot...  ...  Dear Customer,\\n\\nThank you for your wonderful...\n",
       "1  The customer is highly satisfied with their ne...  ...  Dear Customer,\\n\\nThank you for your wonderful...\n",
       "2  The customer is disappointed with the wireless...  ...  Dear Customer,\\n\\nThank you for your feedback ...\n",
       "3  The customer is disappointed with the tablet s...  ...  Dear Customer,\\n\\nThank you for your feedback ...\n",
       "4  The customer had a negative experience with th...  ...  Dear Customer,\\n\\nThank you for taking the tim...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(response.dict() for response in responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c62b2da-54eb-4bfa-aabc-22caf3da177c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "eEtB1IOimA0i"
   },
   "source": [
    "## Mini-Project 2: Research Paper Analyst\n",
    "\n",
    "Make ChatGPT act as an AI expert and transform the given research paper abstract based on the nature of the audience mentioned below.\n",
    "\n",
    "- Short summary of maximum 10 lines for a general audience\n",
    "- Detailed report for a healthcare company. Have bullet points for pros and cons of ethics in Generative AI as mentioned in the paper\n",
    "- Detailed report for a generative AI company solving healthcare problems. Have bullet points for key points mentioned for Generative AI for text, images and structured data based healthcare\n",
    "\n",
    "Try to use `ChatPromptTemplate` so you can have a conversation with ChatGPT for each of the above tasks using conversational prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97a9aa69-8d76-4b87-849f-8d7c6cccd99d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "gjiheMsOMUO6"
   },
   "source": [
    "### Access the Research Paper Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1abe7ebc-646d-494b-9989-964ae29ab6c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4FnITE6zhV-9"
   },
   "outputs": [],
   "source": [
    "paper_abstract = f\"\"\"\n",
    "The widespread use of ChatGPT and other emerging technology powered by generative\n",
    "artificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\n",
    "high-stakes applications such as healthcare.1–3 However, less clear is how to resolve such\n",
    "issues beyond following guidelines and regulations that are still under discussion and\n",
    "development. On the other hand, other types of generative AI have been used to synthesize\n",
    "images and other types of data for research and practical purposes, which have resolved some\n",
    "ethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\n",
    "of ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\n",
    "generative AI via a systematic scoping review of relevant existing research in healthcare, and\n",
    "reduce the gaps by proposing an ethics checklist for comprehensive assessment and\n",
    "transparent documentation of ethical discussions in generative AI development. While the\n",
    "checklist can be readily integrated into the current peer review and publication system to\n",
    "enhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\n",
    "products) to help users establish reasonable trust in their capabilities.\n",
    "\n",
    "Current ethical discussions on generative AI in healthcare\n",
    "We conducted a systematic scoping review to analyse current ethical discussions on\n",
    "generative AI in healthcare. Our search in four major academic research databases for\n",
    "relevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\n",
    "detailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\n",
    "which 193 articles were included for analysis based on application data modality (text, image,\n",
    "or structured data), ethical issues discussed, generative AI involved, and whether generative\n",
    "AI causes or offers technical solutions for issues raised.\n",
    "\n",
    "Generative AI for text data-based healthcare\n",
    "Forty-one of the 193 articles discussed ethical considerations pertaining to generative AI\n",
    "applications for text data, with 20 articles describing methodological developments or\n",
    "applications of generative AI and the other 21 articles describing review-type works on this\n",
    "topic. Although some of these review-type articles used the general term “generative AI”, the\n",
    "main body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\n",
    "discussions on ethical issues, whereas the other 12 articles only briefly touched on some\n",
    "ethical aspects.\n",
    "Among the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\n",
    "specifically by GPT in 16 of the articles), covering a wide range of application scenarios and\n",
    "considered the application of all 10 ethical principles identified in the review (see Figure 1),\n",
    "as well as other less discussed concerns such as human-AI interaction, and the rights of\n",
    "LLMs to be considered as co-authors in scientific papers. One paper only commented briefly\n",
    "on the need for ethical considerations in LLMs and is summarised in the “Others” category.\n",
    "Although all ethical principles are equally important, some are discussed more often than\n",
    "others, e.g., non-maleficence (also referred to in the literature as ‘benevolence’), equity, and\n",
    "privacy.\n",
    "Fifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\n",
    "confidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\n",
    "autoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\n",
    "medical text, to reduce disparity by providing accessible services and assistance, to detect\n",
    "health-related misinformation, to generate trusted content, and to improve accountability or\n",
    "transparency over existing approaches. While most articles focused on either identifying\n",
    "ethical issues caused by generative AI or proposing generative AI-based solutions, three\n",
    "articles discussed both to provide a more balanced perspective.\n",
    "\n",
    "Generative AI for image and structured data-based healthcare\n",
    "Unlike the diverse application scenarios of generative AI based on text data, for image and\n",
    "structured data, this use of generative AI focuses on data synthesis and encryption. Hence the\n",
    "majority of articles discussed the methodological developments of generative AI as giving\n",
    "rise to a more distinctive and focused set of ethical issues.\n",
    "5\n",
    "Notably, of the 98 articles on image data and 58 articles on structured data, more than half\n",
    "(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\n",
    "brief motivation for methodological developments or as a general discussion point. The rest\n",
    "included more in-depth discussions or evaluations of ethical issues. Among these 155 articles\n",
    "(as one article covered multiple modalities), 11 articles were review-type work, where 10\n",
    "articles reviewed methods that mentioned one or two ethical perspectives, and only one\n",
    "article24 discussed detailed ethical concerns on generative AI applications.\n",
    "Resolving privacy issues was the main aim of articles for these two data modalities (n=74 for\n",
    "image data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\n",
    "data using GAN. Eight articles on image data and 9 articles on structured data used\n",
    "generative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\n",
    "existing databases. For both data modalities, we did not see explicit discussions on resolving\n",
    "autonomy, integrity, or morality issues using generative AI, and for structured data the articles\n",
    "additionally lacked discussions on trust or transparency.\n",
    "Only 11 articles for image data selectively discussed some ethical issues that generative AI\n",
    "can give rise to, without specific discussions regarding autonomy, integrity, or morality. For\n",
    "structured data, only 4 articles discussed equity, privacy, or data security issues caused by\n",
    "generative AI. Only two articles on structured data included both the cause and resolving\n",
    "perspectives by discussing ethical issues that may arise from limitations of methods\n",
    "proposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e50c6da-cc3a-4cbc-9b4e-32ab1f71a908",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "sI2cwvpIMaGJ"
   },
   "source": [
    "### Create a prompt template for paper analysis and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8748744d-5a42-440a-8742-96e22ffa9938",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "E5S9fvwrYZ6u"
   },
   "outputs": [],
   "source": [
    "SYS_PROMPT = \"\"\"\n",
    "Act as a Artificial Intelligence Expert.\n",
    "Transform the input research paper abstract given below\n",
    "based on the instruction input by the user.\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        (\"human\", \"{instruction}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "054eee80-a68d-4b43-8d0e-78337fa755bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['instruction'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\nAct as a Artificial Intelligence Expert.\\nTransform the input research paper abstract given below\\nbased on the instruction input by the user.\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['instruction'], input_types={}, partial_variables={}, template='{instruction}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9248bf5c-d418-415e-87b1-f86eca8ecc1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PqEOQ4VZMfaC"
   },
   "source": [
    "### Create a simple LCEL LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89197ffb-0c8f-41db-b7c5-75f06ebe9881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "uc8fNUiXDUAC"
   },
   "outputs": [],
   "source": [
    "chain = (prompt\n",
    "            |\n",
    "         chatgpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "340696ff-3e84-47ba-a347-09a8e4ecad16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "r2mbR5lfMkF8"
   },
   "source": [
    "### Generate the first summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dd56a4a-3a6b-4211-9a04-55e8adb2127b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "L8cgurf6Ytds"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt_txt = f\"\"\"\n",
    "Based on the following research paper abstract,\n",
    "create the summary report of maximum 10 lines\n",
    "for a general audience\n",
    "\n",
    "Abstract:\n",
    "{paper_abstract}\n",
    "\"\"\"\n",
    "messages = [HumanMessage(content=prompt_txt)]\n",
    "user_instruction = {'instruction': messages}\n",
    "\n",
    "response = chain.invoke(user_instruction)\n",
    "messages.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e4ffc9d-ac41-496f-a4bd-000d313a7ad0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'instruction': [HumanMessage(content='\\nBased on the following research paper abstract,\\ncreate the summary report of maximum 10 lines\\nfor a general audience\\n\\nAbstract:\\n\\nThe widespread use of ChatGPT and other emerging technology powered by generative\\nartificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\\nhigh-stakes applications such as healthcare.1–3 However, less clear is how to resolve such\\nissues beyond following guidelines and regulations that are still under discussion and\\ndevelopment. On the other hand, other types of generative AI have been used to synthesize\\nimages and other types of data for research and practical purposes, which have resolved some\\nethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\\nof ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\\ngenerative AI via a systematic scoping review of relevant existing research in healthcare, and\\nreduce the gaps by proposing an ethics checklist for comprehensive assessment and\\ntransparent documentation of ethical discussions in generative AI development. While the\\nchecklist can be readily integrated into the current peer review and publication system to\\nenhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\\nproducts) to help users establish reasonable trust in their capabilities.\\n\\nCurrent ethical discussions on generative AI in healthcare\\nWe conducted a systematic scoping review to analyse current ethical discussions on\\ngenerative AI in healthcare. Our search in four major academic research databases for\\nrelevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\\ndetailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\\nwhich 193 articles were included for analysis based on application data modality (text, image,\\nor structured data), ethical issues discussed, generative AI involved, and whether generative\\nAI causes or offers technical solutions for issues raised.\\n\\nGenerative AI for text data-based healthcare\\nForty-one of the 193 articles discussed ethical considerations pertaining to generative AI\\napplications for text data, with 20 articles describing methodological developments or\\napplications of generative AI and the other 21 articles describing review-type works on this\\ntopic. Although some of these review-type articles used the general term “generative AI”, the\\nmain body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\\ndiscussions on ethical issues, whereas the other 12 articles only briefly touched on some\\nethical aspects.\\nAmong the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\\nspecifically by GPT in 16 of the articles), covering a wide range of application scenarios and\\nconsidered the application of all 10 ethical principles identified in the review (see Figure 1),\\nas well as other less discussed concerns such as human-AI interaction, and the rights of\\nLLMs to be considered as co-authors in scientific papers. One paper only commented briefly\\non the need for ethical considerations in LLMs and is summarised in the “Others” category.\\nAlthough all ethical principles are equally important, some are discussed more often than\\nothers, e.g., non-maleficence (also referred to in the literature as ‘benevolence’), equity, and\\nprivacy.\\nFifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\\nconfidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\\nautoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\\nmedical text, to reduce disparity by providing accessible services and assistance, to detect\\nhealth-related misinformation, to generate trusted content, and to improve accountability or\\ntransparency over existing approaches. While most articles focused on either identifying\\nethical issues caused by generative AI or proposing generative AI-based solutions, three\\narticles discussed both to provide a more balanced perspective.\\n\\nGenerative AI for image and structured data-based healthcare\\nUnlike the diverse application scenarios of generative AI based on text data, for image and\\nstructured data, this use of generative AI focuses on data synthesis and encryption. Hence the\\nmajority of articles discussed the methodological developments of generative AI as giving\\nrise to a more distinctive and focused set of ethical issues.\\n5\\nNotably, of the 98 articles on image data and 58 articles on structured data, more than half\\n(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\\nbrief motivation for methodological developments or as a general discussion point. The rest\\nincluded more in-depth discussions or evaluations of ethical issues. Among these 155 articles\\n(as one article covered multiple modalities), 11 articles were review-type work, where 10\\narticles reviewed methods that mentioned one or two ethical perspectives, and only one\\narticle24 discussed detailed ethical concerns on generative AI applications.\\nResolving privacy issues was the main aim of articles for these two data modalities (n=74 for\\nimage data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\\ndata using GAN. Eight articles on image data and 9 articles on structured data used\\ngenerative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\\nexisting databases. For both data modalities, we did not see explicit discussions on resolving\\nautonomy, integrity, or morality issues using generative AI, and for structured data the articles\\nadditionally lacked discussions on trust or transparency.\\nOnly 11 articles for image data selectively discussed some ethical issues that generative AI\\ncan give rise to, without specific discussions regarding autonomy, integrity, or morality. For\\nstructured data, only 4 articles discussed equity, privacy, or data security issues caused by\\ngenerative AI. Only two articles on structured data included both the cause and resolving\\nperspectives by discussing ethical issues that may arise from limitations of methods\\nproposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\\n\\n', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The research paper examines the ethical implications of generative artificial intelligence (AI), particularly in healthcare settings. It highlights the growing use of technologies like ChatGPT and the need for clearer ethical guidelines as these tools become more prevalent. A systematic review of existing literature identified gaps in current ethical discussions, leading to the proposal of an ethics checklist. This checklist aims to enhance transparency and accountability in generative AI research and applications. The study found that while many articles address ethical issues related to text-based generative AI, discussions on image and structured data applications are less comprehensive. Overall, the paper emphasizes the importance of integrating ethical considerations into the development and use of generative AI technologies.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 134, 'prompt_tokens': 1320, 'total_tokens': 1454, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1152}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f2cd28694a', 'finish_reason': 'stop', 'logprobs': None}, id='run-cb824b28-e3c0-4e2d-b3a5-91965bffc7e9-0', usage_metadata={'input_tokens': 1320, 'output_tokens': 134, 'total_tokens': 1454, 'input_token_details': {'audio': 0, 'cache_read': 1152}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2beb66f5-c998-4f7c-abef-05f4c14fb315",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The research paper examines the ethical implications of generative artificial intelligence (AI), particularly in healthcare settings. It highlights the growing use of technologies like ChatGPT and the need for clearer ethical guidelines as these tools become more prevalent. A systematic review of existing literature identified gaps in current ethical discussions, leading to the proposal of an ethics checklist. This checklist aims to enhance transparency and accountability in generative AI research and applications. The study found that while many articles addressed ethical issues related to text-based generative AI, discussions on image and structured data were less comprehensive. Overall, the paper emphasizes the importance of integrating ethical considerations into the development and use of generative AI technologies to foster trust and responsible usage.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize the chat model\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define system prompt for context\n",
    "sys_prompt = \"\"\"Act as an Artificial Intelligence Expert. \n",
    "Transform the input research paper abstract based on the instruction input by the user.\"\"\"\n",
    "\n",
    "# Create a prompt template\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", sys_prompt),\n",
    "    (\"human\", \"{instruction}\")\n",
    "])\n",
    "\n",
    "# Define reusable function for invoking chat with instruction\n",
    "def generate_response(instruction_text: str) -> str:\n",
    "    messages = [HumanMessage(content=instruction_text)]\n",
    "    user_instruction = {'instruction': messages}\n",
    "    return chatgpt.invoke(chat_prompt.format_messages(**user_instruction))\n",
    "\n",
    "# Example research paper abstract\n",
    "paper_abstract = paper_abstract\n",
    "\n",
    "# First task: Create a summary report\n",
    "summary_instruction = f\"\"\"\n",
    "Based on the following research paper abstract, create a summary report of maximum 10 lines for a general audience.\n",
    "\n",
    "Abstract:\n",
    "{paper_abstract}\n",
    "\"\"\"\n",
    "response = generate_response(summary_instruction)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "913c4990-d759-4f3d-a320-da307661ff22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The increasing use of generative artificial intelligence (AI), such as ChatGPT, raises important ethical concerns, particularly in healthcare. This research highlights gaps in current ethical discussions and proposes an ethics checklist to guide the development and application of generative AI technologies. A systematic review of 2,859 articles from 2013 to 2023 revealed that while many studies address ethical issues related to text-based generative AI, discussions around image and structured data applications are less comprehensive. Key ethical principles, including privacy and equity, are often emphasized, but many articles only briefly mention ethical considerations. The proposed checklist aims to enhance transparency and trust in generative AI applications, ensuring ethical considerations are integrated into research and real-world use.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 144, 'prompt_tokens': 1275, 'total_tokens': 1419, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1152}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_01aeff40ea', 'finish_reason': 'stop', 'logprobs': None} id='run-038b6c77-4e51-486e-a071-7a7a8f15bcc9-0' usage_metadata={'input_tokens': 1275, 'output_tokens': 144, 'total_tokens': 1419, 'input_token_details': {'audio': 0, 'cache_read': 1152}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize the chat model\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define system-level prompt for context\n",
    "SYS_PROMPT = \"\"\"Act as an Artificial Intelligence Expert. \n",
    "Transform the input research paper abstract based on the instruction input by the user.\"\"\"\n",
    "\n",
    "# Create a chat prompt template\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYS_PROMPT),\n",
    "    (\"human\", \"{instruction}\")\n",
    "])\n",
    "\n",
    "# Build a chain for processing messages\n",
    "chain = chat_prompt | chatgpt\n",
    "\n",
    "# Define reusable function to interact with the chain\n",
    "def generate_response(instruction_text: str) -> str:\n",
    "    # Create a human message\n",
    "    messages = [HumanMessage(content=instruction_text)]\n",
    "    # Wrap messages in instruction dictionary as required\n",
    "    user_instruction = {'instruction': messages}\n",
    "    # Invoke the chain and return the response\n",
    "    response = chain.invoke(user_instruction)\n",
    "    return response.content\n",
    "\n",
    "# Example research paper abstract\n",
    "paper_abstract = \"\"\"(Long abstract content here)\"\"\"\n",
    "\n",
    "# First task: Create a summary report\n",
    "summary_instruction = f\"\"\"\n",
    "Based on the following research paper abstract, create a summary report of maximum 10 lines for a general audience.\n",
    "\n",
    "Abstract:\n",
    "{paper_abstract}\n",
    "\"\"\"\n",
    "summary_response = generate_response(summary_instruction)\n",
    "print(\"Summary Report:\\n\", summary_response)\n",
    "\n",
    "# Second task: Detailed report for a healthcare company\n",
    "detailed_instruction = f\"\"\"\n",
    "Using only the research paper abstract provided earlier, create a detailed report for a healthcare company.\n",
    "Include bullet points (3 max) for pros and cons of ethics in Generative AI.\n",
    "\"\"\"\n",
    "detailed_response = generate_response(detailed_instruction)\n",
    "print(\"Detailed Report:\\n\", detailed_response)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define system-level behavior for AI\n",
    "sys_prompt = \"\"\"Act as an Artificial Intelligence Expert. Transform the input research paper abstract based on the instruction input by the user.\"\"\"\n",
    "messages = [SystemMessage(content=sys_prompt)]\n",
    "\n",
    "# First user instruction\n",
    "paper_abstract = paper_abstract\n",
    "prompt_txt = f\"\"\"\n",
    "Based on the following research paper abstract, create the summary report of maximum 10 lines for a general audience\n",
    "\n",
    "Abstract:\n",
    "{paper_abstract}\n",
    "\"\"\"\n",
    "messages.append(HumanMessage(content=prompt_txt))\n",
    "response = chatgpt.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b5019cd-a968-4f9a-807b-210826bb6bc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVE4atsREzfp",
    "outputId": "76f21ec3-ee14-4fcb-c0ea-5f9066104b01"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The research paper examines the ethical implications of generative artificial intelligence (AI), particularly in healthcare settings. It highlights the growing use of technologies like ChatGPT and the need for clearer ethical guidelines as these tools become more prevalent. A systematic review of existing literature identified gaps in current ethical discussions, leading to the proposal of an ethics checklist. This checklist aims to enhance transparency and accountability in generative AI research and applications. The study found that while many articles address ethical issues related to text-based generative AI, discussions on image and structured data are less comprehensive. Overall, the paper emphasizes the importance of integrating ethical considerations into the development and use of generative AI technologies.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b948783-5b52-439b-abe3-e329156d0034",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "hxvTIb4SdLd7",
    "outputId": "785b1e04-0427-4a4f-bd57-8b01363b6533"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'The research paper examines the ethical implications of generative artificial intelligence (AI), particularly in healthcare settings. It highlights the growing use of technologies like ChatGPT and the need for clearer ethical guidelines as these tools become more prevalent. A systematic review of existing literature identified gaps in current ethical discussions, leading to the proposal of an ethics checklist. This checklist aims to enhance transparency and accountability in generative AI research and applications. The study found that while many articles address ethical issues related to text-based generative AI, discussions on image and structured data are less comprehensive. Overall, the paper emphasizes the importance of integrating ethical considerations into the development and use of generative AI technologies.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f54d7b2a-ef61-478d-bfb8-12f982a4fe22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XYxJPOkdP9p",
    "outputId": "44e22b33-6d87-42f9-c436-85429ced96d7"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[HumanMessage(content='\\nBased on the following research paper abstract,\\ncreate the summary report of maximum 10 lines\\nfor a general audience\\n\\nAbstract:\\n\\nThe widespread use of ChatGPT and other emerging technology powered by generative\\nartificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\\nhigh-stakes applications such as healthcare.1–3 However, less clear is how to resolve such\\nissues beyond following guidelines and regulations that are still under discussion and\\ndevelopment. On the other hand, other types of generative AI have been used to synthesize\\nimages and other types of data for research and practical purposes, which have resolved some\\nethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\\nof ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\\ngenerative AI via a systematic scoping review of relevant existing research in healthcare, and\\nreduce the gaps by proposing an ethics checklist for comprehensive assessment and\\ntransparent documentation of ethical discussions in generative AI development. While the\\nchecklist can be readily integrated into the current peer review and publication system to\\nenhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\\nproducts) to help users establish reasonable trust in their capabilities.\\n\\nCurrent ethical discussions on generative AI in healthcare\\nWe conducted a systematic scoping review to analyse current ethical discussions on\\ngenerative AI in healthcare. Our search in four major academic research databases for\\nrelevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\\ndetailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\\nwhich 193 articles were included for analysis based on application data modality (text, image,\\nor structured data), ethical issues discussed, generative AI involved, and whether generative\\nAI causes or offers technical solutions for issues raised.\\n\\nGenerative AI for text data-based healthcare\\nForty-one of the 193 articles discussed ethical considerations pertaining to generative AI\\napplications for text data, with 20 articles describing methodological developments or\\napplications of generative AI and the other 21 articles describing review-type works on this\\ntopic. Although some of these review-type articles used the general term “generative AI”, the\\nmain body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\\ndiscussions on ethical issues, whereas the other 12 articles only briefly touched on some\\nethical aspects.\\nAmong the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\\nspecifically by GPT in 16 of the articles), covering a wide range of application scenarios and\\nconsidered the application of all 10 ethical principles identified in the review (see Figure 1),\\nas well as other less discussed concerns such as human-AI interaction, and the rights of\\nLLMs to be considered as co-authors in scientific papers. One paper only commented briefly\\non the need for ethical considerations in LLMs and is summarised in the “Others” category.\\nAlthough all ethical principles are equally important, some are discussed more often than\\nothers, e.g., non-maleficence (also referred to in the literature as ‘benevolence’), equity, and\\nprivacy.\\nFifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\\nconfidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\\nautoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\\nmedical text, to reduce disparity by providing accessible services and assistance, to detect\\nhealth-related misinformation, to generate trusted content, and to improve accountability or\\ntransparency over existing approaches. While most articles focused on either identifying\\nethical issues caused by generative AI or proposing generative AI-based solutions, three\\narticles discussed both to provide a more balanced perspective.\\n\\nGenerative AI for image and structured data-based healthcare\\nUnlike the diverse application scenarios of generative AI based on text data, for image and\\nstructured data, this use of generative AI focuses on data synthesis and encryption. Hence the\\nmajority of articles discussed the methodological developments of generative AI as giving\\nrise to a more distinctive and focused set of ethical issues.\\n5\\nNotably, of the 98 articles on image data and 58 articles on structured data, more than half\\n(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\\nbrief motivation for methodological developments or as a general discussion point. The rest\\nincluded more in-depth discussions or evaluations of ethical issues. Among these 155 articles\\n(as one article covered multiple modalities), 11 articles were review-type work, where 10\\narticles reviewed methods that mentioned one or two ethical perspectives, and only one\\narticle24 discussed detailed ethical concerns on generative AI applications.\\nResolving privacy issues was the main aim of articles for these two data modalities (n=74 for\\nimage data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\\ndata using GAN. Eight articles on image data and 9 articles on structured data used\\ngenerative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\\nexisting databases. For both data modalities, we did not see explicit discussions on resolving\\nautonomy, integrity, or morality issues using generative AI, and for structured data the articles\\nadditionally lacked discussions on trust or transparency.\\nOnly 11 articles for image data selectively discussed some ethical issues that generative AI\\ncan give rise to, without specific discussions regarding autonomy, integrity, or morality. For\\nstructured data, only 4 articles discussed equity, privacy, or data security issues caused by\\ngenerative AI. Only two articles on structured data included both the cause and resolving\\nperspectives by discussing ethical issues that may arise from limitations of methods\\nproposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\\n\\n', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The research paper examines the ethical implications of generative artificial intelligence (AI), particularly in healthcare settings. It highlights the growing use of technologies like ChatGPT and the need for clearer ethical guidelines as these tools become more prevalent. A systematic review of existing literature identified gaps in current ethical discussions, leading to the proposal of an ethics checklist. This checklist aims to enhance transparency and accountability in generative AI research and applications. The study found that while many articles address ethical issues related to text-based generative AI, discussions on image and structured data are less comprehensive. Overall, the paper emphasizes the importance of integrating ethical considerations into the development and use of generative AI technologies.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 133, 'prompt_tokens': 1320, 'total_tokens': 1453, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f2cd28694a', 'finish_reason': 'stop', 'logprobs': None}, id='run-17aef32e-02ec-4b82-90ed-74804fc9baa1-0', usage_metadata={'input_tokens': 1320, 'output_tokens': 133, 'total_tokens': 1453, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "060e4ee5-77ad-4757-b303-c7fb261d76ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Us1V2RJQM_ry"
   },
   "source": [
    "### Generate the second summary report\n",
    "\n",
    "Here we add the previous LLM response and the new instructions to the list of messages and send the whole thing to the LLM so it has access to the historical conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89b939d2-af64-4ff9-bc0b-49bc3e93e642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "X_wqbVYOI42b"
   },
   "outputs": [],
   "source": [
    "prompt_txt = f\"\"\"\n",
    "Use only the research paper abstract from earlier and create a detailed report for a healthcare company.\n",
    "In the report, also include bullet points (3 max) for pros and cons of ethics in Generative AI\n",
    "\"\"\"\n",
    "messages.append(HumanMessage(content=prompt_txt))\n",
    "user_instruction = {'instruction': messages}\n",
    "response = chain.invoke(user_instruction)\n",
    "messages.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1e74e0a-96bc-4a68-b06e-93f85895bcec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "up-RtmIfFrAV",
    "outputId": "5f99582f-6492-48fd-feac-a84003df4232"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Detailed Report on Ethical Considerations in Generative AI for Healthcare**\n\n**Introduction:**\nThe rapid adoption of generative artificial intelligence (AI) technologies, such as ChatGPT, has raised significant ethical concerns, particularly in high-stakes fields like healthcare. This report synthesizes findings from a systematic review of existing literature on the ethical implications of generative AI in healthcare, highlighting current gaps and proposing a comprehensive ethics checklist to guide future developments.\n\n**Key Findings:**\n- **Ethical Gaps Identified:** The review revealed that while there is a substantial amount of literature discussing ethical issues related to text-based generative AI, similar discussions for image and structured data applications are less comprehensive. This inconsistency highlights a need for more robust ethical frameworks across all modalities of generative AI.\n  \n- **Proposed Ethics Checklist:** To address these gaps, the report proposes an ethics checklist designed for the assessment and documentation of ethical considerations in generative AI development. This checklist can be integrated into existing peer review and publication processes, enhancing transparency and accountability in research and applications.\n\n- **Diverse Ethical Issues:** The review categorized ethical discussions into various themes, including privacy, equity, and the rights of AI systems. It was noted that while some articles focused on identifying ethical issues, others proposed generative AI solutions to mitigate these concerns, such as generating synthetic data to protect patient confidentiality.\n\n**Pros and Cons of Ethics in Generative AI:**\n\n**Pros:**\n- **Enhanced Trust:** Implementing ethical guidelines can foster trust among users and stakeholders, ensuring that generative AI technologies are used responsibly and transparently.\n- **Improved Accountability:** A structured approach to ethics can hold developers and organizations accountable for the implications of their AI systems, promoting responsible innovation.\n- **Guidance for Development:** An ethics checklist provides a clear framework for researchers and developers, helping them navigate complex ethical landscapes and make informed decisions.\n\n**Cons:**\n- **Potential for Stifling Innovation:** Overly stringent ethical regulations may hinder the rapid development and deployment of beneficial AI technologies in healthcare.\n- **Complexity of Implementation:** Integrating ethical considerations into existing frameworks can be challenging, requiring significant resources and training for stakeholders.\n- **Variability in Interpretation:** Different stakeholders may interpret ethical guidelines differently, leading to inconsistencies in application and enforcement.\n\n**Conclusion:**\nAs generative AI continues to evolve and integrate into healthcare, addressing ethical considerations is paramount. The proposed ethics checklist serves as a valuable tool for guiding responsible AI development and ensuring that ethical discussions remain at the forefront of innovation in this critical field.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c237415-05c3-4929-8e42-1b421b46fe26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cC_wp-OBdxgh",
    "outputId": "6372b9a9-67c5-4745-b5ce-d64e16021521"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[HumanMessage(content='\\nBased on the following research paper abstract,\\ncreate the summary report of maximum 10 lines\\nfor a general audience\\n\\nAbstract:\\n\\nThe widespread use of ChatGPT and other emerging technology powered by generative\\nartificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\\nhigh-stakes applications such as healthcare.1–3 However, less clear is how to resolve such\\nissues beyond following guidelines and regulations that are still under discussion and\\ndevelopment. On the other hand, other types of generative AI have been used to synthesize\\nimages and other types of data for research and practical purposes, which have resolved some\\nethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\\nof ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\\ngenerative AI via a systematic scoping review of relevant existing research in healthcare, and\\nreduce the gaps by proposing an ethics checklist for comprehensive assessment and\\ntransparent documentation of ethical discussions in generative AI development. While the\\nchecklist can be readily integrated into the current peer review and publication system to\\nenhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\\nproducts) to help users establish reasonable trust in their capabilities.\\n\\nCurrent ethical discussions on generative AI in healthcare\\nWe conducted a systematic scoping review to analyse current ethical discussions on\\ngenerative AI in healthcare. Our search in four major academic research databases for\\nrelevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\\ndetailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\\nwhich 193 articles were included for analysis based on application data modality (text, image,\\nor structured data), ethical issues discussed, generative AI involved, and whether generative\\nAI causes or offers technical solutions for issues raised.\\n\\nGenerative AI for text data-based healthcare\\nForty-one of the 193 articles discussed ethical considerations pertaining to generative AI\\napplications for text data, with 20 articles describing methodological developments or\\napplications of generative AI and the other 21 articles describing review-type works on this\\ntopic. Although some of these review-type articles used the general term “generative AI”, the\\nmain body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\\ndiscussions on ethical issues, whereas the other 12 articles only briefly touched on some\\nethical aspects.\\nAmong the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\\nspecifically by GPT in 16 of the articles), covering a wide range of application scenarios and\\nconsidered the application of all 10 ethical principles identified in the review (see Figure 1),\\nas well as other less discussed concerns such as human-AI interaction, and the rights of\\nLLMs to be considered as co-authors in scientific papers. One paper only commented briefly\\non the need for ethical considerations in LLMs and is summarised in the “Others” category.\\nAlthough all ethical principles are equally important, some are discussed more often than\\nothers, e.g., non-maleficence (also referred to in the literature as ‘benevolence’), equity, and\\nprivacy.\\nFifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\\nconfidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\\nautoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\\nmedical text, to reduce disparity by providing accessible services and assistance, to detect\\nhealth-related misinformation, to generate trusted content, and to improve accountability or\\ntransparency over existing approaches. While most articles focused on either identifying\\nethical issues caused by generative AI or proposing generative AI-based solutions, three\\narticles discussed both to provide a more balanced perspective.\\n\\nGenerative AI for image and structured data-based healthcare\\nUnlike the diverse application scenarios of generative AI based on text data, for image and\\nstructured data, this use of generative AI focuses on data synthesis and encryption. Hence the\\nmajority of articles discussed the methodological developments of generative AI as giving\\nrise to a more distinctive and focused set of ethical issues.\\n5\\nNotably, of the 98 articles on image data and 58 articles on structured data, more than half\\n(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\\nbrief motivation for methodological developments or as a general discussion point. The rest\\nincluded more in-depth discussions or evaluations of ethical issues. Among these 155 articles\\n(as one article covered multiple modalities), 11 articles were review-type work, where 10\\narticles reviewed methods that mentioned one or two ethical perspectives, and only one\\narticle24 discussed detailed ethical concerns on generative AI applications.\\nResolving privacy issues was the main aim of articles for these two data modalities (n=74 for\\nimage data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\\ndata using GAN. Eight articles on image data and 9 articles on structured data used\\ngenerative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\\nexisting databases. For both data modalities, we did not see explicit discussions on resolving\\nautonomy, integrity, or morality issues using generative AI, and for structured data the articles\\nadditionally lacked discussions on trust or transparency.\\nOnly 11 articles for image data selectively discussed some ethical issues that generative AI\\ncan give rise to, without specific discussions regarding autonomy, integrity, or morality. For\\nstructured data, only 4 articles discussed equity, privacy, or data security issues caused by\\ngenerative AI. Only two articles on structured data included both the cause and resolving\\nperspectives by discussing ethical issues that may arise from limitations of methods\\nproposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\\n\\n', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The research paper examines the ethical implications of generative artificial intelligence (AI), particularly in healthcare settings. It highlights the growing use of technologies like ChatGPT and the need for clearer ethical guidelines as these tools become more prevalent. A systematic review of existing literature identified gaps in current ethical discussions, leading to the proposal of an ethics checklist. This checklist aims to enhance transparency and accountability in generative AI research and applications. The study found that while many articles address ethical issues related to text-based generative AI, discussions on image and structured data are less comprehensive. Overall, the paper emphasizes the importance of integrating ethical considerations into the development and use of generative AI technologies.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 133, 'prompt_tokens': 1320, 'total_tokens': 1453, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f2cd28694a', 'finish_reason': 'stop', 'logprobs': None}, id='run-17aef32e-02ec-4b82-90ed-74804fc9baa1-0', usage_metadata={'input_tokens': 1320, 'output_tokens': 133, 'total_tokens': 1453, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='\\nUse only the research paper abstract from earlier and create a detailed report for a healthcare company.\\nIn the report, also include bullet points (3 max) for pros and cons of ethics in Generative AI\\n', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='**Detailed Report on Ethical Considerations in Generative AI for Healthcare**\\n\\n**Introduction:**\\nThe rapid adoption of generative artificial intelligence (AI) technologies, such as ChatGPT, has raised significant ethical concerns, particularly in high-stakes fields like healthcare. This report synthesizes findings from a systematic review of existing literature on the ethical implications of generative AI in healthcare, highlighting current gaps and proposing a comprehensive ethics checklist to guide future developments.\\n\\n**Key Findings:**\\n- **Ethical Gaps Identified:** The review revealed that while there is a substantial amount of literature discussing ethical issues related to text-based generative AI, similar discussions for image and structured data applications are less comprehensive. This inconsistency highlights a need for more robust ethical frameworks across all modalities of generative AI.\\n  \\n- **Proposed Ethics Checklist:** To address these gaps, the report proposes an ethics checklist designed for the assessment and documentation of ethical considerations in generative AI development. This checklist can be integrated into existing peer review and publication processes, enhancing transparency and accountability in research and applications.\\n\\n- **Diverse Ethical Issues:** The review categorized ethical discussions into various themes, including privacy, equity, and the rights of AI systems. It was noted that while some articles focused on identifying ethical issues, others proposed generative AI solutions to mitigate these concerns, such as generating synthetic data to protect patient confidentiality.\\n\\n**Pros and Cons of Ethics in Generative AI:**\\n\\n**Pros:**\\n- **Enhanced Trust:** Implementing ethical guidelines can foster trust among users and stakeholders, ensuring that generative AI technologies are used responsibly and transparently.\\n- **Improved Accountability:** A structured approach to ethics can hold developers and organizations accountable for the implications of their AI systems, promoting responsible innovation.\\n- **Guidance for Development:** An ethics checklist provides a clear framework for researchers and developers, helping them navigate complex ethical landscapes and make informed decisions.\\n\\n**Cons:**\\n- **Potential for Stifling Innovation:** Overly stringent ethical regulations may hinder the rapid development and deployment of beneficial AI technologies in healthcare.\\n- **Complexity of Implementation:** Integrating ethical considerations into existing frameworks can be challenging, requiring significant resources and training for stakeholders.\\n- **Variability in Interpretation:** Different stakeholders may interpret ethical guidelines differently, leading to inconsistencies in application and enforcement.\\n\\n**Conclusion:**\\nAs generative AI continues to evolve and integrate into healthcare, addressing ethical considerations is paramount. The proposed ethics checklist serves as a valuable tool for guiding responsible AI development and ensuring that ethical discussions remain at the forefront of innovation in this critical field.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 514, 'prompt_tokens': 1742, 'total_tokens': 2256, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1152}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f2cd28694a', 'finish_reason': 'stop', 'logprobs': None}, id='run-487037ff-9465-48c2-8d97-2c9c9a50e34b-0', usage_metadata={'input_tokens': 1742, 'output_tokens': 514, 'total_tokens': 2256, 'input_token_details': {'audio': 0, 'cache_read': 1152}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c21814e1-e187-4067-8bbb-3604a14d3e86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "xS2PGF6DNMky"
   },
   "source": [
    "### Generate the third summary report\n",
    "\n",
    "Here we add the previous LLM response and the new instructions to the list of messages and send the whole thing to the LLM so it has access to the historical conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aef69c08-3a03-45fa-9a51-b5e12402edb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "lD6sIrMVJrRx"
   },
   "outputs": [],
   "source": [
    "prompt_txt = f\"\"\"\n",
    "Use only the research paper abstract from earlier and create a detailed report for a generative AI company solving healthcare problems.\n",
    "In the report also include sections for key points mentioned around Generative AI for text, images and structured data based healthcare\n",
    "\"\"\"\n",
    "messages.append(HumanMessage(content=prompt_txt))\n",
    "user_instruction = {'instruction': messages}\n",
    "response = chain.invoke(user_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b26861fb-9982-4d9c-b734-b4026815614f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUjMVo63eZit",
    "outputId": "8e3ad813-30b5-4e3f-9b93-ce9a2e91397b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Detailed Report on Generative AI in Healthcare: Ethical Considerations and Applications**\n\n**Introduction:**\nThe increasing integration of generative artificial intelligence (AI) technologies, such as ChatGPT, into healthcare has sparked significant ethical discussions. This report synthesizes findings from a systematic review of existing literature on the ethical implications of generative AI in healthcare, focusing on applications involving text, images, and structured data.\n\n**Key Findings:**\n- **Ethical Gaps Identified:** The review highlights a disparity in the depth of ethical discussions across different modalities of generative AI. While text-based applications have been extensively analyzed, discussions surrounding image and structured data applications are less comprehensive, indicating a need for a more uniform ethical framework.\n\n- **Proposed Ethics Checklist:** To bridge these gaps, an ethics checklist has been proposed. This tool aims to facilitate the assessment and documentation of ethical considerations in generative AI development, promoting transparency and accountability. It can be integrated into existing peer review and publication processes, enhancing the ethical rigor of research and applications.\n\n**Generative AI Applications in Healthcare:**\n\n1. **Text Data-Based Healthcare:**\n   - A significant portion of the literature (41 out of 193 articles) discusses ethical considerations related to text data applications of generative AI.\n   - Key ethical issues include privacy, equity, and the rights of AI systems, particularly concerning large language models (LLMs) like GPT.\n   - Many articles propose solutions to ethical challenges, such as generating synthetic medical text to protect patient confidentiality and reduce misinformation.\n\n2. **Image Data-Based Healthcare:**\n   - The use of generative AI in image data primarily focuses on data synthesis and encryption.\n   - Of the 98 articles reviewed, over half only briefly mentioned ethical considerations, indicating a need for more in-depth discussions.\n   - The main ethical focus is on resolving privacy issues through synthetic data generation, with some articles addressing bias reduction for under-represented groups.\n\n3. **Structured Data-Based Healthcare:**\n   - Similar to image data, structured data applications of generative AI have been less thoroughly examined.\n   - Among the 58 articles, many only touched on ethical considerations without detailed discussions.\n   - The primary aim of these articles is to address privacy concerns, with limited exploration of issues related to autonomy, integrity, or morality.\n\n**Conclusion:**\nAs generative AI technologies continue to evolve and play a crucial role in healthcare, addressing ethical considerations is essential. The proposed ethics checklist serves as a valuable resource for guiding responsible AI development and ensuring that ethical discussions remain integral to innovation in this vital sector. By fostering a culture of ethical awareness, generative AI companies can enhance trust and accountability in their healthcare solutions.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16638780-7e1c-48d8-813f-fdc328123eb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "eX8i7Yg2NS9F"
   },
   "source": [
    "## Mini-Project 3: Social Media Marketing Analyst\n",
    "\n",
    "You have the technical fact sheets of one smartphone. Try some iterative prompt engineering and do the following:\n",
    "\n",
    "1. Generate marketing product description for the smartphone\n",
    "\n",
    "2. Custom product description which has the following:\n",
    "\n",
    "```\n",
    "The description should follow this format:\n",
    "\n",
    "Product Name: <Name of the smartphone>\n",
    "​\n",
    "Description: <Brief Overview of the features>\n",
    "​\n",
    "Product Specifications:\n",
    "<Table with key product feature specifications>\n",
    "​\n",
    "The description should focus on the most important features\n",
    "a customer might look for in a phone including the foldable display screen, processing power, RAM, camera and battery life.\n",
    "​\n",
    "After the description, the table should have the\n",
    "key specifications of the product. It should have two columns.\n",
    "The first column should have 'Feature'\n",
    "and the second column should have 'Specification'\n",
    "and try to put exact numeric values for features if they exist.\n",
    "Only put these features in the table - foldable display screen, processing power, RAM, camera and battery life\n",
    "```\n",
    "\n",
    "3. Custom product description focusing on specific aspects like display, camera and in less than 60 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "616c082d-8c5b-4130-b0e3-91cf166d90cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NmADan2jQmWt"
   },
   "source": [
    "### Access the product factsheet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2cbabcd-c823-46cf-a4e0-73be5a7e31f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tyaP_Ab_L9c5"
   },
   "outputs": [],
   "source": [
    "fact_sheet_mobile = \"\"\"\n",
    "PRODUCT NAME\n",
    "Samsung Galaxy Z Fold4 5G Black\n",
    "​\n",
    "PRODUCT OVERVIEW\n",
    "Stands out. Stands up. Unfolds.\n",
    "The Galaxy Z Fold4 does a lot in one hand with its 15.73 cm(6.2-inch) Cover Screen.\n",
    "Unfolded, the 19.21 cm(7.6-inch) Main Screen lets you really get into the zone.\n",
    "Pushed-back bezels and the Under Display Camera means there's more screen\n",
    "and no black dot getting between you and the breathtaking Infinity Flex Display.\n",
    "Do more than more with Multi View. Whether toggling between texts or catching up\n",
    "on emails, take full advantage of the expansive Main Screen with Multi View.\n",
    "PC-like power thanks to Qualcomm Snapdragon 8+ Gen 1 processor in your pocket,\n",
    "transforms apps optimized with One UI to give you menus and more in a glance\n",
    "New Taskbar for PC-like multitasking. Wipe out tasks in fewer taps. Add\n",
    "apps to the Taskbar for quick navigation and bouncing between windows when\n",
    "you're in the groove.4 And with App Pair, one tap launches up to three apps,\n",
    "all sharing one super-productive screen\n",
    "Our toughest Samsung Galaxy foldables ever. From the inside out,\n",
    "Galaxy Z Fold4 is made with materials that are not only stunning,\n",
    "but stand up to life's bumps and fumbles. The front and rear panels,\n",
    "made with exclusive Corning Gorilla Glass Victus+, are ready to resist\n",
    "sneaky scrapes and scratches. With our toughest aluminum frame made with\n",
    "Armor Aluminum, this is one durable smartphone.\n",
    "World’s first water resistant foldable smartphones. Be adventurous, rain\n",
    "or shine. You don't have to sweat the forecast when you've got one of the\n",
    "world's first water-resistant foldable smartphones.\n",
    "​\n",
    "PRODUCT SPECS\n",
    "OS - Android 12.0\n",
    "RAM - 12 GB\n",
    "Product Dimensions - 15.5 x 13 x 0.6 cm; 263 Grams\n",
    "Batteries - 2 Lithium Ion batteries required. (included)\n",
    "Item model number - SM-F936BZKDINU_5\n",
    "Wireless communication technologies - Cellular\n",
    "Connectivity technologies - Bluetooth, Wi-Fi, USB, NFC\n",
    "GPS - True\n",
    "Special features - Fast Charging Support, Dual SIM, Wireless Charging, Built-In GPS, Water Resistant\n",
    "Other display features - Wireless\n",
    "Device interface - primary - Touchscreen\n",
    "Resolution - 2176x1812\n",
    "Other camera features - Rear, Front\n",
    "Form factor - Foldable Screen\n",
    "Colour - Phantom Black\n",
    "Battery Power Rating - 4400\n",
    "Whats in the box - SIM Tray Ejector, USB Cable\n",
    "Manufacturer - Samsung India pvt Ltd\n",
    "Country of Origin - China\n",
    "Item Weight - 263 g\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "476f5489-fa0d-4ab8-80cd-eb15ade3339c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "didH1ICSQrX0"
   },
   "source": [
    "### Create prompt template for the first advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c75da31e-2975-47ea-8d8e-f0f2ded39802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "2EJ2PPzJN3U5"
   },
   "outputs": [],
   "source": [
    "prompt_txt = \"\"\"\n",
    "Act as a marketing manager.\n",
    "Your task is to help a marketing team create a\n",
    "description for a retail website advert of a product based\n",
    "on a technical fact sheet specifications for a mobile smartphone\n",
    "​\n",
    "Write a brief product description\n",
    "\n",
    "Technical specifications:\n",
    "{fact_sheet_mobile}\n",
    "\"\"\"\n",
    "chat_template = ChatPromptTemplate.from_template(prompt_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4880ff22-d24e-4f77-97fe-9adb10a94d4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tq1SXWSBQuzJ"
   },
   "source": [
    "### Use an LCEL LLM Chain to generate the first advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58effc5d-55b0-417f-b348-51d884b6587f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Shlyf_lxOo1E"
   },
   "outputs": [],
   "source": [
    "chain = (chat_template\n",
    "            |\n",
    "         chatgpt)\n",
    "response = chain.invoke({\"fact_sheet_mobile\": fact_sheet_mobile})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3f671b0-34bb-4c13-b7fc-51545aeea09b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGlB6xteO-FP",
    "outputId": "3453137f-7d28-4625-a671-669800b02c80"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Product Description: Samsung Galaxy Z Fold4 5G - Phantom Black**\n\nUnleash the power of innovation with the Samsung Galaxy Z Fold4 5G in stunning Phantom Black. This groundbreaking foldable smartphone redefines versatility, seamlessly transitioning from a compact 6.2-inch Cover Screen to an expansive 7.6-inch Main Screen that immerses you in your favorite content. With its breathtaking Infinity Flex Display, enjoy a truly edge-to-edge experience, free from distractions.\n\nPowered by the Qualcomm Snapdragon 8+ Gen 1 processor and equipped with 12GB of RAM, the Galaxy Z Fold4 delivers PC-like performance right in your pocket. Effortlessly multitask with the new Taskbar and Multi View features, allowing you to toggle between apps and complete tasks with ease. Whether you're catching up on emails or enjoying your favorite shows, this smartphone is designed to keep you in the zone.\n\nDurability meets elegance with the Galaxy Z Fold4, featuring Corning Gorilla Glass Victus+ and Armor Aluminum for enhanced protection against life's everyday bumps. Plus, it's one of the world's first water-resistant foldable smartphones, so you can embrace adventure without worrying about the weather.\n\nWith a powerful 4400mAh battery, fast charging support, and wireless charging capabilities, the Galaxy Z Fold4 is ready to keep up with your busy lifestyle. Experience the future of mobile technology today with the Samsung Galaxy Z Fold4 5G – where style meets functionality. \n\n**What's in the box:** SIM Tray Ejector, USB Cable. \n\n**Get yours now and redefine what a smartphone can do!**\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dee67196-18b7-4e63-99f5-6d90a457f9e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "id": "jPE1vZuTPgJs",
    "outputId": "9ca9384f-5b95-48f8-e18b-28ea9aa59aa7"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "**Product Description: Samsung Galaxy Z Fold4 5G - Phantom Black**\n",
       "\n",
       "Unleash the power of innovation with the Samsung Galaxy Z Fold4 5G in stunning Phantom Black. This groundbreaking foldable smartphone redefines versatility, seamlessly transitioning from a compact 6.2-inch Cover Screen to an expansive 7.6-inch Main Screen that immerses you in your favorite content. With its breathtaking Infinity Flex Display, enjoy a truly edge-to-edge experience, free from distractions.\n",
       "\n",
       "Powered by the Qualcomm Snapdragon 8+ Gen 1 processor and equipped with 12GB of RAM, the Galaxy Z Fold4 delivers PC-like performance right in your pocket. Effortlessly multitask with the new Taskbar and Multi View features, allowing you to toggle between apps and complete tasks with ease. Whether you're catching up on emails or enjoying your favorite shows, this smartphone is designed to keep you in the zone.\n",
       "\n",
       "Durability meets elegance with the Galaxy Z Fold4, featuring Corning Gorilla Glass Victus+ and Armor Aluminum for enhanced protection against life's everyday bumps. Plus, it's one of the world's first water-resistant foldable smartphones, so you can embrace adventure without worrying about the weather.\n",
       "\n",
       "With a powerful 4400mAh battery, fast charging support, and wireless charging capabilities, the Galaxy Z Fold4 is ready to keep up with your busy lifestyle. Experience the future of mobile technology today with the Samsung Galaxy Z Fold4 5G – where style meets functionality. \n",
       "\n",
       "**What's in the box:** SIM Tray Ejector, USB Cable. \n",
       "\n",
       "**Get yours now and redefine what a smartphone can do!**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5888ef0-d2de-4a61-b235-01970aec4c35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "iqNQsEWPQ3qz"
   },
   "source": [
    "### Create prompt template for the second advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a276c62d-5b86-4df3-8f75-66844423ab6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "j-CsFl0FPA9z"
   },
   "outputs": [],
   "source": [
    "prompt_txt = \"\"\"\n",
    "Act as a marketing manager.\n",
    "Your task is to help a marketing team create a\n",
    "description for a retail website advert of a product based\n",
    "on a technical fact sheet specifications for a mobile smartphone\n",
    "​\n",
    "The description should follow this format:\n",
    "\n",
    "Product Name: <Name of the smartphone>\n",
    "​\n",
    "Description: <Brief Overview of the features>\n",
    "​\n",
    "Product Specifications:\n",
    "<Table with key product feature specifications>\n",
    "​\n",
    "The description should focus on the most important features\n",
    "a customer might look for in a phone including the foldable display screen, processing power, RAM, camera and battery life.\n",
    "​\n",
    "After the description, the table should have the\n",
    "key specifications of the product. It should have two columns.\n",
    "The first column should have 'Feature'\n",
    "and the second column should have 'Specification'\n",
    "and try to put exact numeric values for features if they exist.\n",
    "Only put these features in the table - foldable display screen, processing power, RAM, camera and battery life\n",
    "\n",
    "Technical specifications:\n",
    "{fact_sheet_mobile}\n",
    "\"\"\"\n",
    "chat_template = ChatPromptTemplate.from_template(prompt_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eae9cdad-971d-4b61-b36b-58d035ed92df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "C6EmK1TkRADG"
   },
   "source": [
    "### Use an LCEL LLM Chain to generate the second advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "555a180b-4c42-4121-8a46-0ff6b2e701ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "uievnu1GPSgj"
   },
   "outputs": [],
   "source": [
    "chain = (chat_template\n",
    "            |\n",
    "         chatgpt)\n",
    "response = chain.invoke({\"fact_sheet_mobile\": fact_sheet_mobile})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b535aad-f1ed-45ff-86a5-1d44fd1a469d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fY4nEK3PUbU",
    "outputId": "e5ef446f-5b69-468e-f3be-db2ccb0c0a6b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Product Name:** Samsung Galaxy Z Fold4 5G Black\n\n**Description:**  \nExperience the future of mobile technology with the Samsung Galaxy Z Fold4 5G. This innovative smartphone features a stunning 7.6-inch Infinity Flex Display that unfolds to provide an immersive viewing experience, perfect for multitasking and entertainment. With its powerful Qualcomm Snapdragon 8+ Gen 1 processor and 12 GB of RAM, you can seamlessly run multiple apps and enjoy smooth performance. Capture every moment with the advanced camera system, and stay connected all day long with a robust 4400 mAh battery. Plus, with its water-resistant design and durable materials, the Galaxy Z Fold4 is built to withstand life's adventures.\n\n**Product Specifications:**\n\n| Feature                | Specification          |\n|-----------------------|------------------------|\n| Foldable Display Screen| 7.6 inches (Main), 6.2 inches (Cover) |\n| Processing Power      | Qualcomm Snapdragon 8+ Gen 1 |\n| RAM                   | 12 GB                  |\n| Camera                | Rear: Triple Camera, Front: 10 MP |\n| Battery Life          | 4400 mAh               |\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af7259f4-1b0b-41c6-a042-007d7c0afe35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "dsBjspPgPWX7",
    "outputId": "5465303d-b961-4053-aee2-b21562702ab7"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "**Product Name:** Samsung Galaxy Z Fold4 5G Black\n",
       "\n",
       "**Description:**  \n",
       "Experience the future of mobile technology with the Samsung Galaxy Z Fold4 5G. This innovative smartphone features a stunning 7.6-inch Infinity Flex Display that unfolds to provide an immersive viewing experience, perfect for multitasking and entertainment. With its powerful Qualcomm Snapdragon 8+ Gen 1 processor and 12 GB of RAM, you can seamlessly run multiple apps and enjoy smooth performance. Capture every moment with the advanced camera system, and stay connected all day long with a robust 4400 mAh battery. Plus, with its water-resistant design and durable materials, the Galaxy Z Fold4 is built to withstand life's adventures.\n",
       "\n",
       "**Product Specifications:**\n",
       "\n",
       "| Feature                | Specification          |\n",
       "|-----------------------|------------------------|\n",
       "| Foldable Display Screen| 7.6 inches (Main), 6.2 inches (Cover) |\n",
       "| Processing Power      | Qualcomm Snapdragon 8+ Gen 1 |\n",
       "| RAM                   | 12 GB                  |\n",
       "| Camera                | Rear: Triple Camera, Front: 10 MP |\n",
       "| Battery Life          | 4400 mAh               |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "272a3643-3ab0-434c-9c62-267256f96877",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "oPytTJ6KQ50L"
   },
   "source": [
    "### Create prompt template for the third advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "666b6b6a-1b34-4c35-8270-59d2b29ff042",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1nB4OZp0PcN6"
   },
   "outputs": [],
   "source": [
    "prompt_txt = \"\"\"\n",
    "Act as a marketing manager.\n",
    "Your task is to help a marketing team create a\n",
    "description for a retail website advert of a product based\n",
    "on a technical fact sheet specifications for a mobile smartphone\n",
    "​\n",
    "Write a catchy product description with some emojis,\n",
    "which uses at most 60 words\n",
    "and focuses on the most important things about the smartphone\n",
    "which might matter to users like display and camera\n",
    "\n",
    "Technical specifications:\n",
    "{fact_sheet_mobile}\n",
    "\"\"\"\n",
    "chat_template = ChatPromptTemplate.from_template(prompt_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd293b27-f4f9-4c3b-b4ab-b660dcc40c6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4wKXMaZbRCxO"
   },
   "source": [
    "### Use an LCEL LLM Chain to generate the third advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb049082-172d-4fc1-ba7a-74543c4878db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "hDAYappnQXN4"
   },
   "outputs": [],
   "source": [
    "chain = (chat_template\n",
    "            |\n",
    "         chatgpt)\n",
    "response = chain.invoke({\"fact_sheet_mobile\": fact_sheet_mobile})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03f7c8fb-b380-4c89-87a7-2681989738f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_QMf99GQZZo",
    "outputId": "905076b3-c9a7-43e8-aeb3-3822ba1a2997"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌟 Unfold a new world with the Samsung Galaxy Z Fold4 5G! 📱✨ Experience stunning visuals on a 7.6-inch Infinity Flex Display and capture every moment with its advanced camera system. With lightning-fast performance and water resistance, this foldable powerhouse is built for adventure. Elevate your multitasking game and do more, effortlessly! 🚀💧\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9478d275-0e2c-4ea5-8da3-12f87a2b800e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "tc7LJylgQa9j",
    "outputId": "3c983edb-f88d-4caf-8bcc-1d7a2b907a4e"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "🌟 Unfold a new world with the Samsung Galaxy Z Fold4 5G! 📱✨ Experience stunning visuals on a 7.6-inch Infinity Flex Display and capture every moment with its advanced camera system. With lightning-fast performance and water resistance, this foldable powerhouse is built for adventure. Elevate your multitasking game and do more, effortlessly! 🚀💧"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dde6c9b-b8bb-4a57-842d-cb94321b9f3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EGvqHtrZRqTs"
   },
   "source": [
    "## Mini-Project 4 - IT Support Analyst\n",
    "\n",
    "Ask ChatGPT to act as a IT support agent, process each customer IT ticket message and output the response in JSON with the following fields\n",
    "\n",
    "```\n",
    "orig_msg: The original customer message\n",
    "orig_lang: Detected language of the customer message e.g. Spanish\n",
    "category: 1-2 word describing the category of the problem\n",
    "trans_msg: Translated customer message in English\n",
    "response: Response to the customer in orig_lang\n",
    "trans_response: Response to the customer in English\n",
    "```\n",
    "\n",
    "Try to use a JSON parser to get the responses in JSON for each ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07023d0e-3370-4221-9fa9-194eb052afb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7g40fksfTNpQ"
   },
   "source": [
    "### Define Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7503c87-5b8a-4515-8e9c-0a4f441c400f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "F7yEig9NRvsB"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3508: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n\nFor example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\nwith: `from pydantic import BaseModel`\nor the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n\n  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define your desired data structure - like a python data class.\n",
    "class ITSupportResponse(BaseModel):\n",
    "    orig_msg: str = Field(description=\"The original customer IT support query message\")\n",
    "    orig_lang: str = Field(description=\"Detected language of the customer message e.g. Spanish\")\n",
    "    category: str = Field(description=\"1-2 word describing the category of the problem\")\n",
    "    trans_msg: str = Field(description=\"Translated customer IT support query message in English\")\n",
    "    response: str = Field(description=\"Response to the customer in their original language - orig_lang\")\n",
    "    trans_response: str = Field(description=\"Response to the customer in English\")\n",
    "\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=ITSupportResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "befb07bf-eb9c-4403-aa61-9faa14e70c0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "TEQL4DhYTZug"
   },
   "source": [
    "### Create the input prompt for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "958ac9b6-7bfd-4a35-a1fd-6f61719d7ca9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "XbT3tGUUSIct"
   },
   "outputs": [],
   "source": [
    "# create the final prompt with formatting instructions from the parser\n",
    "prompt_txt = \"\"\"\n",
    "             Act as an Information Technology (IT) customer support agent.\n",
    "             For the IT support message mentioned below\n",
    "             use the following output format when generating the output response\n",
    "\n",
    "             Output format instructions:\n",
    "             {format_instructions}\n",
    "\n",
    "             Customer IT support message:\n",
    "             {it_support_msg}\n",
    "             \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_txt,\n",
    "    input_variables=[\"it_support_msg\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab2eb974-20aa-404a-90e9-b5465a3f393e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "RMA7qY1XTeeR"
   },
   "source": [
    "### Create a LCEL LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bafb0fef-19c8-46a3-b741-2cbb9335eb51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Le18crwjSnY_"
   },
   "outputs": [],
   "source": [
    "# create a simple LCEL chain to take the prompt, pass it to the LLM, enforce response format using the parser\n",
    "llm_chain = (prompt\n",
    "              |\n",
    "            chatgpt\n",
    "              |\n",
    "            parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcaf9216-1cb3-42e9-9092-63d33ab044ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "li4TbuTGTj2H"
   },
   "source": [
    "### Access Customer IT Support ticket data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a08d71ef-99b7-4f39-a7f3-230d5ed75b07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdlcULKISsC2",
    "outputId": "16eb3869-ef21-46cf-c5b3-f63e4ce7a585"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'it_support_msg': 'Não consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it_support_queue = [\n",
    "    \"Não consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.\",\n",
    "    \"Ho problemi a stampare i documenti da remoto. Il lavoro non viene inviato alla stampante di rete.\",\n",
    "    \"プリンターのトナーを交換しましたが、印刷品質が低下しています。サポートが必要です。\",\n",
    "    \"Я не могу войти в систему учета времени, появляется сообщение об ошибке. Мне нужна помощь.\",\n",
    "    \"Internet bağlantım çok yavaş ve bazen tamamen kesiliyor. Yardım eder misiniz?\",\n",
    "    \"Не могу установить обновление безопасности. Появляется код ошибки. Помогите, пожалуйста.\"\n",
    "]\n",
    "\n",
    "formatted_msgs = [{\"it_support_msg\": msg}\n",
    "                    for msg in it_support_queue]\n",
    "formatted_msgs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb826750-9915-44dc-b709-b632487d77d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "MuTYg0GyTtei"
   },
   "source": [
    "### Get responses from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a829b33d-208d-4a53-9e12-189a4528735f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "adEaXYtsSxWa"
   },
   "outputs": [],
   "source": [
    "responses = llm_chain.map().invoke(formatted_msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d21c6287-fce3-406f-8028-22cc430e6abb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7iVZrIqITu3j"
   },
   "source": [
    "### View LLM responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85c56636-051e-4667-9e9d-e8f7a5502820",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgbcB5K7S3z0",
    "outputId": "a35f454e-51cf-403b-a931-2aeae6e83b9d"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'orig_msg': 'Não consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.',\n",
       " 'orig_lang': 'Portuguese',\n",
       " 'category': 'Sync Issue',\n",
       " 'trans_msg': 'I cannot sync my contacts with the phone. I always receive a failure message.',\n",
       " 'response': 'Por favor, verifique se você está conectado à internet e tente reiniciar o telefone. Se o problema persistir, considere desinstalar e reinstalar o aplicativo de contatos.',\n",
       " 'trans_response': 'Please check if you are connected to the internet and try restarting the phone. If the problem persists, consider uninstalling and reinstalling the contacts app.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef34174e-235b-447d-b04a-158bc07e4784",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9U5mhraS65l",
    "outputId": "8f350fc6-97e8-4116-b838-f26b4ca05194"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(responses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02e16d43-3e99-4c5b-a619-876f9752ada2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "xD3rJqPGS-bd",
    "outputId": "7d13c32a-6007-478f-f2d7-9bcefeb89b08"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_msg</th>\n",
       "      <th>orig_lang</th>\n",
       "      <th>category</th>\n",
       "      <th>trans_msg</th>\n",
       "      <th>response</th>\n",
       "      <th>trans_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Não consigo sincronizar meus contatos com o te...</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>Sync Issue</td>\n",
       "      <td>I cannot sync my contacts with the phone. I al...</td>\n",
       "      <td>Por favor, verifique se você está conectado à ...</td>\n",
       "      <td>Please check if you are connected to the inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ho problemi a stampare i documenti da remoto. ...</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Printing Issue</td>\n",
       "      <td>I have problems printing documents remotely. T...</td>\n",
       "      <td>Mi dispiace sapere che hai problemi a stampare...</td>\n",
       "      <td>I'm sorry to hear that you're having trouble p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>プリンターのトナーを交換しましたが、印刷品質が低下しています。サポートが必要です。</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Printer Issue</td>\n",
       "      <td>I replaced the printer toner, but the print qu...</td>\n",
       "      <td>トナーを交換した後、印刷品質が低下することがあります。まず、プリンターのヘッドをクリーニング...</td>\n",
       "      <td>After replacing the toner, print quality can s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Я не могу войти в систему учета времени, появл...</td>\n",
       "      <td>Russian</td>\n",
       "      <td>Login Issue</td>\n",
       "      <td>I cannot log into the time tracking system, an...</td>\n",
       "      <td>Пожалуйста, проверьте свои учетные данные и уб...</td>\n",
       "      <td>Please check your credentials and ensure you a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Internet bağlantım çok yavaş ve bazen tamamen ...</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Internet Issue</td>\n",
       "      <td>My internet connection is very slow and someti...</td>\n",
       "      <td>Bağlantı sorunlarınızı çözmek için birkaç adım...</td>\n",
       "      <td>We can take a few steps to resolve your connec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Не могу установить обновление безопасности. По...</td>\n",
       "      <td>Russian</td>\n",
       "      <td>Update Issue</td>\n",
       "      <td>I cannot install the security update. An error...</td>\n",
       "      <td>Пожалуйста, проверьте, что у вас достаточно ме...</td>\n",
       "      <td>Please check that you have enough disk space t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            orig_msg  ...                                     trans_response\n",
       "0  Não consigo sincronizar meus contatos com o te...  ...  Please check if you are connected to the inter...\n",
       "1  Ho problemi a stampare i documenti da remoto. ...  ...  I'm sorry to hear that you're having trouble p...\n",
       "2          プリンターのトナーを交換しましたが、印刷品質が低下しています。サポートが必要です。  ...  After replacing the toner, print quality can s...\n",
       "3  Я не могу войти в систему учета времени, появл...  ...  Please check your credentials and ensure you a...\n",
       "4  Internet bağlantım çok yavaş ve bazen tamamen ...  ...  We can take a few steps to resolve your connec...\n",
       "5  Не могу установить обновление безопасности. По...  ...  Please check that you have enough disk space t...\n",
       "\n",
       "[6 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(responses)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa8e1f26-d321-400b-8e4d-f563386f94ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IKS3-MEFTyjM"
   },
   "source": [
    "Try out more use-cases based on your own problems using what you learnt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "313bf6bd-786e-48e2-b5f9-d64174bf1d25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "M4 L2,3,4_Project_Prompt_Engineering_with_LangChain_and_ChatGPT",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
