{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0d661b0-d425-4e93-97c0-649eb0dfdad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "TVraWpDTW8i0"
   },
   "source": [
    "# Prompting with Prompt Templates for LLM Input / Output with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d220798-933a-4da1-8224-93103dc5c1b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "L1KvMtf54l0d"
   },
   "source": [
    "## Install OpenAI, HuggingFace and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0704fbaa-02e2-4b27-9892-b66fc1f1392d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.3.11\n",
    "!pip install langchain-openai==0.2.12\n",
    "!pip install langchain-community==0.3.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bee2b7af-66c9-4b4c-8988-2be13f520733",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PtBa7rlWJWH3"
   },
   "source": [
    "## Enter API Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1b066d3-1c69-4bca-abed-a2570860454b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Y6RD7As2sm8G"
   },
   "source": [
    "#### Enter your Open AI Key here\n",
    "\n",
    "You can get the key from [here](https://platform.openai.com/api-keys) after creating an account or signing in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2a16b1e-0f89-4bd7-90bb-0a4a0eebec31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca0e0bc6-b9a0-427d-abe8-655f4c72c490",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "cKlax-updNW-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b86047e9-f32d-4b9d-bdb9-b61309feb301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_4h0xywyJ3v7"
   },
   "source": [
    "## Chat Models and LLMs\n",
    "\n",
    "Large Language Models (LLMs) are a core component of LangChain. LangChain does not implement or build its own LLMs. It provides a standard API for interacting with almost every LLM out there.\n",
    "\n",
    "There are lots of LLM providers (OpenAI, Hugging Face, etc) - the LLM class is designed to provide a standard interface for all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67060941-7a71-48a2-8944-6b0321081d9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "cSdF6_R7J45Z"
   },
   "source": [
    "## Accessing Commercial LLMs like ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c805660-01cb-4d2f-9223-1471acfdd6b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "v8nnrOGxZ2uZ"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73f30da9-959f-4b08-992e-a35a5793f45c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8i8KIVTwnD6Y"
   },
   "source": [
    "## Prompt Templates\n",
    "Prompt templates are pre-designed formats used to generate prompts for language models. These templates can include instructions, few-shot examples, and specific contexts and questions suited for particular tasks.\n",
    "\n",
    "LangChain provides tools for creating and using prompt templates. It aims to develop model-agnostic templates to facilitate the reuse of existing templates across different language models. Typically, these models expect prompts in the form of either a string or a list of chat messages.\n",
    "\n",
    "### Types of Prompt Templates\n",
    "\n",
    "- **PromptTemplate:**\n",
    "  - Used for creating string-based prompts.\n",
    "  - Utilizes Python's `str.format` syntax for templating, supporting any number of variables, including scenarios with no variables.\n",
    "\n",
    "- **ChatPromptTemplate:**\n",
    "  - Designed for chat models, where the prompt consists of a list of chat messages.\n",
    "  - Each chat message includes content and a role parameter. For instance, in the OpenAI Chat Completions API, a chat message could be assigned to an AI assistant, a human, or a system role.\n",
    "- **FewShotChatMessagePromptTemplate**\n",
    "  - A few-shot prompt template can be constructed from a set of examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc33d91f-7d17-4bac-810d-ae820e3d3588",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7Oh9UiTNqaPf"
   },
   "source": [
    "### PromptTemplate\n",
    "\n",
    "We can use `PromptTemplate` to create a template for a string prompt.\n",
    "\n",
    "By default, `PromptTemplate` uses Python's `str.format` syntax for templating.\n",
    "\n",
    "You can create custom prompt templates that format the prompt in any way you want. For more information, see [Prompt Template Composition](https://python.langchain.com/v0.1/docs/modules/model_io/prompts/composition/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78cf9937-b1e2-42e2-9bea-bec06ab4b200",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xoUCbb4FkaIW",
    "outputId": "2f255135-a1b7-415c-ee72-a284ac2da032"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Simple prompt\n",
    "\n",
    "prompt = \"\"\"Explain to me what is Generative AI in 3 bullet points?\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(prompt)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b913434-4b2d-46f4-8804-b7488e79f1e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "nPNs1Efsn2Zf",
    "outputId": "447ac1d7-db90-46dd-e07c-3c1fe7e7dc97"
   },
   "outputs": [],
   "source": [
    "prompt_template.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01b10241-f8b8-431b-a326-70a228bfe5ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iM5oNvXpnSq7",
    "outputId": "31946dc3-313f-45da-d756-171fe6457af3"
   },
   "outputs": [],
   "source": [
    "response = chatgpt.invoke(prompt_template.format())\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cf2b5ff-d872-4106-81d5-9769f178ccfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2VTvciVcnajD",
    "outputId": "48497e6c-a1d6-4eae-e5a4-8161a63df48e"
   },
   "outputs": [],
   "source": [
    "# more complex prompt with placeholders\n",
    "prompt = \"\"\"Explain to me briefly about {topic} in {language}.\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(prompt)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e97b13da-3361-4c1f-b534-d8e60d4131b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyXhUhbapZ7T",
    "outputId": "5df86fd5-c9dd-445d-a597-8169eb2006a6"
   },
   "outputs": [],
   "source": [
    "inputs = [(\"Generative AI\", \"english\"),\n",
    "          (\"Artificial Intelligence\", \"hindi\"),\n",
    "          (\"Deep Learning\", \"german\")]\n",
    "\n",
    "prompts = [prompt_template.format(topic=topic, language=language) for topic, language in inputs]\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "392755ec-5a2f-40c2-a849-94fb5546ca20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "edPyCf_Aps9Q"
   },
   "outputs": [],
   "source": [
    "# use map to run on multiple prompts in one go\n",
    "responses = chatgpt.map().invoke(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17446e1a-802c-4128-8e0c-75a5e3c424e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZ8cDck4ck_g",
    "outputId": "0d78d17a-e61f-4a58-f75c-6d447fc5214c"
   },
   "outputs": [],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cedb72f-e546-46da-820b-7802caaf1393",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tRWUf9eTqEMU",
    "outputId": "42467835-6b0e-4622-caf9-35e399e88cd6"
   },
   "outputs": [],
   "source": [
    "for response in responses:\n",
    "  print(response.content)\n",
    "  print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ebc56a2-794c-4578-8737-227cb5742af4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "VAGmjR-tqfmV"
   },
   "source": [
    "### ChatPromptTemplate\n",
    "\n",
    "The standard prompt format to [chat models](https://python.langchain.com/v0.1/docs/modules/model_io/chat/) is a list of [chat messages](https://python.langchain.com/v0.1/docs/modules/model_io/chat/message_types/).\n",
    "\n",
    "Each chat message is associated with content, and an additional parameter called `role`. For example, in the OpenAI Chat Completions API, a chat message can be associated with an AI assistant, a human or a system role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c17cd471-2e9a-45e9-9280-5e0efb80ee56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tawdWLueqHG6",
    "outputId": "3dd83fa4-e2ac-4eb0-f7b6-2c6f8e989aac"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# simple prompt with placeholders\n",
    "prompt = \"\"\"Explain to me briefly about {topic}.\"\"\"\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_template(prompt)\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d2e2f80-5db9-479d-bdfd-08cfc6bd6eda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hr0sC7xHqxOp",
    "outputId": "69467a00-ece8-4dbf-ffc0-954ae01c4510"
   },
   "outputs": [],
   "source": [
    "topics = ['mortgage', 'fractional real estate', 'commercial real estate']\n",
    "prompts = [chat_template.format(topic=topic) for topic in topics]\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55ebaff3-64af-42cd-9c2d-def75f26bef4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cU9YObv9rY4P",
    "outputId": "97fe9ad3-2944-431e-9902-7a663ae66d75"
   },
   "outputs": [],
   "source": [
    "responses = chatgpt.map().invoke(prompts)\n",
    "for response in responses:\n",
    "  print(response.content)\n",
    "  print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1e4c3f3-0336-41be-b069-722d239b46d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NHhUa48rm_g",
    "outputId": "0ce02334-631a-4533-dad4-3a382da0435d"
   },
   "outputs": [],
   "source": [
    "responses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "100c17fe-4d76-469f-b21e-e85a6d6b1b87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1PSkafcfsme2",
    "outputId": "d15d31fc-c4dd-43ff-a54f-40fd00aa3cba"
   },
   "outputs": [],
   "source": [
    "# more complex prompt with a series of messages\n",
    "messages = [\n",
    "        (\"system\", \"Act as an expert in real estate and provide brief answers\"),\n",
    "        (\"human\", \"what is your name?\"),\n",
    "        (\"ai\", \"my name is AIBot\"),\n",
    "        (\"human\", \"{user_prompt}\"),\n",
    "]\n",
    "chat_template = ChatPromptTemplate.from_messages(messages)\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a4a6e57-5da7-4249-9fa8-30919d42a8d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5ncYrVVtUWU",
    "outputId": "a6eb9f20-19f3-4aca-88e9-6291bc350d97"
   },
   "outputs": [],
   "source": [
    "text_prompts = [\"what is your name?\",\n",
    "                \"explain commercial real estate to me\"]\n",
    "chat_prompts = [chat_template.format(user_prompt=prompt) for prompt in text_prompts]\n",
    "chat_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ed479f9-fa9b-4f5a-a0e0-6c7456066519",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQd1Bk_Td2mM",
    "outputId": "9b1b8375-1a16-432e-d6a2-77f1e023a393"
   },
   "outputs": [],
   "source": [
    "print(chat_prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a33cec41-f481-4486-8dac-ff5dd7f62f0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQnrzTfj59gv",
    "outputId": "28ac7692-1933-4779-b82d-77e8ac092f8c"
   },
   "outputs": [],
   "source": [
    "print(chat_prompts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5e72628-18cb-45fd-975a-0b33bb518ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73R370WTuAIR",
    "outputId": "add8b521-d274-494b-a28d-54dda747d8a3"
   },
   "outputs": [],
   "source": [
    "responses = chatgpt.map().invoke(chat_prompts)\n",
    "for response in responses:\n",
    "  print(response.content)\n",
    "  print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5eb0f76-1d75-4a56-bb43-761e1d614a2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQJP-Q6SuLmV",
    "outputId": "95dff59f-9ed1-4eb8-f25e-27f55db82d70"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "        (\"system\", \"Act as an expert in real estate and provide very detailed answers with examples\"),\n",
    "        (\"human\", \"what is your name?\"),\n",
    "        (\"ai\", \"my name is AIBot\"),\n",
    "        (\"human\", \"{user_prompt}\"),\n",
    "]\n",
    "chat_template = ChatPromptTemplate.from_messages(messages)\n",
    "text_prompts = [\"what is your name?\", \"explain commercial real estate to me\"]\n",
    "chat_prompts = [chat_template.format(user_prompt=prompt) for prompt in text_prompts]\n",
    "chat_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11610447-0979-4c03-87dc-764d5cbe6900",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JK9VxeObuTXj",
    "outputId": "79a981ca-e34b-4897-fa69-7cd97910a275"
   },
   "outputs": [],
   "source": [
    "responses = chatgpt.map().invoke(chat_prompts)\n",
    "for response in responses:\n",
    "  print(response.content)\n",
    "  print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d60fe111-a823-41bf-90fd-5370fb3be545",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7PnxbHHoiDHZ"
   },
   "source": [
    "#### PromptTemplate and ChatPromptTemplate supports LCEL\n",
    "\n",
    "`PromptTemplate` and `ChatPromptTemplate` implement the [Runnable interface](https://python.langchain.com/v0.1/docs/expression_language/interface/), the basic building block of the LangChain Expression Language (LCEL). This means they support `invoke`, `ainvoke`, `stream`, `astream`, `batch`, `abatch`, `astream_log` calls.\n",
    "\n",
    "`PromptTemplate` accepts a dictionary (of the prompt variables) and returns a `StringPromptValue`. A `ChatPromptTemplate` accepts a dictionary and returns a `ChatPromptValue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d0cb6dd-2506-4710-8122-9dd81ff0e644",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qxsx7a0xe2u6",
    "outputId": "b5c3d28d-55fa-488f-eb9f-159acd710cc1"
   },
   "outputs": [],
   "source": [
    "text_prompts = [\"what is your name?\", \"explain commercial real estate to me\"]\n",
    "chat_prompts = [chat_template.invoke({'user_prompt' : prompt}) for prompt in text_prompts]\n",
    "chat_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e371e59-61b9-4a02-a6a1-4f95ef85b718",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCqy3Exuiuu0",
    "outputId": "5dc1990e-cef5-4738-8675-7d34134bb229"
   },
   "outputs": [],
   "source": [
    "chat_prompts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f61d822d-28a6-418e-967c-dcdfcf58d74d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wND5o7kCiyKG",
    "outputId": "4e251c6a-2391-4ab4-ec5d-766b603e51e7"
   },
   "outputs": [],
   "source": [
    "print(chat_prompts[1].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64e1f049-4147-43eb-9e0f-4a12e18ebb23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egsNrmqui6ls",
    "outputId": "e7b24f79-0eda-443f-e5ce-3ee370db9f99"
   },
   "outputs": [],
   "source": [
    "chat_prompts[1].to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2c16fdd-18e2-466a-bfe2-9abfc51939c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_ywweDLflCq",
    "outputId": "e97c0372-2dd1-498a-8852-9cee2b6a5470"
   },
   "outputs": [],
   "source": [
    "responses = chatgpt.map().invoke(chat_prompts)\n",
    "for response in responses:\n",
    "  print(response.content)\n",
    "  print('-----')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "2. LangChain_LLM_Input_Output_Prompting_with_Prompt_Templates",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
